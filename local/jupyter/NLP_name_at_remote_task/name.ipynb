{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# まとめ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('前', '砂'), ('砂', '糖'), ('糖', '一'), ('一', '郎'), ('郎', '1'), ('1', '9')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_parts = '前砂糖一郎19'\n",
    "ngram(text_parts, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 表記揺れ 解決方法まとめ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 正規化\n",
    "- n-gram 活用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 複数の正規化処理をまとめたneologdnという便利なライブラリがある\n",
    "\n",
    "> 土屋祐一郎. 15stepで踏襲 自然言語処理アプリケーション開発入門 (Japanese Edition) (Kindle の位置No.1065-1066). Kindle 版. \n",
    "\n",
    "> 表記のゆれを吸収し、ある一定の表記に統一する処理を行うことが一般的です。これを文字列の正規化（normalization）といいます。\n",
    "\n",
    "> 土屋祐一郎. 15stepで踏襲 自然言語処理アプリケーション開発入門 (Japanese Edition) (Kindle の位置No.1057-1058). Kindle 版. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neologdn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Name: neologdn\n",
      "Version: 0.4\n",
      "Summary: Japanese text normalizer for mecab-neologd\n",
      "Home-page: http://github.com/ikegami-yukino/neologdn\n",
      "Author: Yukino Ikegami\n",
      "Author-email: yknikgm@gmail.com\n",
      "License: Apache Software License\n",
      "Location: /opt/conda/lib/python3.7/site-packages\n",
      "Requires: \n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show neologdn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '履歴書2019年12月25日現在ふりがなさとういちろう名前砂糖一郎1995年1月1日生（満24歳）男・女ふりがなとうきょうとちよだくさざんたわー電話000-0000-0000Emailtest1@sample.comふりがな電話Email年月学歴・職歴学歴20104東京都砂糖高等学校入学20133東京都砂糖高等学校卒業20134東京都菓子大学入学20173東京都菓子大学卒業職歴201710Donuts株式会社入社現在に至る以上現住所〒100-0000東京都千代田区サザンタワー現住所〒(現住所以外に連絡を希望する場合のみ入力)証明写真縦36mm〜40mm横24mm〜30mm本人単身胸から上裏面のりづけ年･2年･2年月学歴・職歴年月免許・資格201212TOEIC公開テスト800点取得志望動機・特技・アピールポイントなどDonutsは、サービスやゲームにおいて1年、2年で終わってしまうようなものではなく、世の中に何らかの価値をもたらし、100年先にもその価値が残り続けるものを目指してプロダクト創りをしています。そのために社会や時流に変化をもたらすもの創り出していこうという想いを込めてサービスを作り出しています。通勤時間電車約1時間00分扶養家族数（配偶者を除く）0人配偶者有・無配偶者の扶養義務有・無本人希望欄（特に給料・職種・勤務時間・勤務地・その他について希望があれば記入）Donutsは、サービスやゲームにおいて1年、2年で終わってしまうようなものではなく、世の中に何らかの価値をもたらし、100年先にもその価値が残り続けるものを目指してプロダクト創りをしています。そのために社会や時流に変化をもたらすもの創り出していこうという想いを込めてサービスを作り出しています。'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "履歴書2019年12月25日現在ふりがなさとういちろう名前砂糖一郎1995年1月1日生（満24歳）男・女ふりがなとうきょうとちよだくさざんたわー電話000-0000-0000Emailtest1@sample.comふりがな電話Email年月学歴・職歴学歴20104東京都砂糖高等学校入学20133東京都砂糖高等学校卒業20134東京都菓子大学入学20173東京都菓子大学卒業職歴201710Donuts株式会社入社現在に至る以上現住所〒100-0000東京都千代田区サザンタワー現住所〒(現住所以外に連絡を希望する場合のみ入力)証明写真縦36mm〜40mm横24mm〜30mm本人単身胸から上裏面のりづけ年･2年･2年月学歴・職歴年月免許・資格201212TOEIC公開テスト800点取得志望動機・特技・アピールポイントなどDonutsは、サービスやゲームにおいて1年、2年で終わってしまうようなものではなく、世の中に何らかの価値をもたらし、100年先にもその価値が残り続けるものを目指してプロダクト創りをしています。そのために社会や時流に変化をもたらすもの創り出していこうという想いを込めてサービスを作り出しています。通勤時間電車約1時間00分扶養家族数（配偶者を除く）0人配偶者有・無配偶者の扶養義務有・無本人希望欄（特に給料・職種・勤務時間・勤務地・その他について希望があれば記入）Donutsは、サービスやゲームにおいて1年、2年で終わってしまうようなものではなく、世の中に何らかの価値をもたらし、100年先にもその価値が残り続けるものを目指してプロダクト創りをしています。そのために社会や時流に変化をもたらすもの創り出していこうという想いを込めてサービスを作り出しています。\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_text = neologdn.normalize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "履歴書2019年12月25日現在ふりがなさとういちろう名前砂糖一郎1995年1月1日生(満24歳)男・女ふりがなとうきょうとちよだくさざんたわー電話000-0000-0000emailtest1@sample.comふりがな電話email年月学歴・職歴学歴20104東京都砂糖高等学校入学20133東京都砂糖高等学校卒業20134東京都菓子大学入学20173東京都菓子大学卒業職歴201710donuts株式会社入社現在に至る以上現住所〒100-0000東京都千代田区サザンタワー現住所〒(現住所以外に連絡を希望する場合のみ入力)証明写真縦36mm40mm横24mm30mm本人単身胸から上裏面のりづけ年・2年・2年月学歴・職歴年月免許・資格201212toeic公開テスト800点取得志望動機・特技・アピールポイントなどdonutsは、サービスやゲームにおいて1年、2年で終わってしまうようなものではなく、世の中に何らかの価値をもたらし、100年先にもその価値が残り続けるものを目指してプロダクト創りをしています。そのために社会や時流に変化をもたらすもの創り出していこうという想いを込めてサービスを作り出しています。通勤時間電車約1時間00分扶養家族数(配偶者を除く)0人配偶者有・無配偶者の扶養義務有・無本人希望欄(特に給料・職種・勤務時間・勤務地・その他について希望があれば記入)donutsは、サービスやゲームにおいて1年、2年で終わってしまうようなものではなく、世の中に何らかの価値をもたらし、100年先にもその価値が残り続けるものを目指してプロダクト創りをしています。そのために社会や時流に変化をもたらすもの創り出していこうという想いを込めてサービスを作り出しています。\n"
     ]
    }
   ],
   "source": [
    "print(normalize_text.lower()) # 英字を小文字に変換"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 訓練データの作成\n",
    "\n",
    "ここはtrigramで生成してみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = ['明石海人', '秋山康之進', '青木恵哉', '暁烏敏', '明石海人', '麻生豊', '青柳文蔵']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['明石海人', '秋山康之進', '青木恵哉', '暁烏敏', '明石海人', '麻生豊', '青柳文蔵']"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = name_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'明石海人'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['明', '石', '海', '人']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n-gram & 訓練データの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram(words, n):\n",
    "    return list(zip(*(words[i:] for i in range(n))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('明', '石'), ('石', '海'), ('海', '人')]"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram(a, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般的なノイズデータtextdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ふりがなさとういちろう名前明石海人1995年1月1日生(満24歳)男', 'ふりがなさとういちろう名前秋山康之進1995年1月1日生(満24歳)男', 'ふりがなさとういちろう名前青木恵哉1995年1月1日生(満24歳)男', 'ふりがなさとういちろう名前暁烏敏1995年1月1日生(満24歳)男', 'ふりがなさとういちろう名前明石海人1995年1月1日生(満24歳)男', 'ふりがなさとういちろう名前麻生豊1995年1月1日生(満24歳)男', 'ふりがなさとういちろう名前青柳文蔵1995年1月1日生(満24歳)男']\n"
     ]
    }
   ],
   "source": [
    "t_p = []\n",
    "\n",
    "for ii in range(len(name_list)):\n",
    "    noize_text = 'ふりがなさとういちろう名前' + name_list[ii] + '1995年1月1日生(満24歳)男'\n",
    "    t_p.append(noize_text)\n",
    "\n",
    "print(t_p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def ngram(words, n):\n",
    "\n",
    "    return list(zip(*(words[i:] for i in range(n))))\n",
    "\n",
    "def con(num, text):\n",
    "    s = '{},'.format(num)\n",
    "    for i in text:\n",
    "        s += i\n",
    "    return s.split(',') \n",
    "\n",
    "\n",
    "cc = []\n",
    "num_ngram = 15\n",
    "for num in range(len(t_p)):\n",
    "    text_parts = t_p[num]\n",
    "    n = ngram(text_parts, num_ngram)\n",
    "    c = [con(num, t) for t in ngram(text_parts, num_ngram)]\n",
    "    cc.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open(\"training_data.csv\", \"w\", newline='') as f:\n",
    "    w = csv.writer(f, delimiter=\",\")\n",
    "    w.writerow(['label', 'text'])\n",
    "    for c in cc:\n",
    "        for  data_list in c:       \n",
    "            w.writerow(data_list)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label,text\r",
      "\r\n",
      "0,ふりがなさとういちろう名前明石\r",
      "\r\n",
      "0,りがなさとういちろう名前明石海\r",
      "\r\n",
      "0,がなさとういちろう名前明石海人\r",
      "\r\n",
      "0,なさとういちろう名前明石海人1\r",
      "\r\n",
      "0,さとういちろう名前明石海人19\r",
      "\r\n",
      "0,とういちろう名前明石海人199\r",
      "\r\n",
      "0,ういちろう名前明石海人1995\r",
      "\r\n",
      "0,いちろう名前明石海人1995年\r",
      "\r\n",
      "0,ちろう名前明石海人1995年1\r",
      "\r\n",
      "0,ろう名前明石海人1995年1月\r",
      "\r\n",
      "0,う名前明石海人1995年1月1\r",
      "\r\n",
      "0,名前明石海人1995年1月1日\r",
      "\r\n",
      "0,前明石海人1995年1月1日生\r",
      "\r\n",
      "0,明石海人1995年1月1日生(\r",
      "\r\n",
      "0,石海人1995年1月1日生(満\r",
      "\r\n",
      "0,海人1995年1月1日生(満2\r",
      "\r\n",
      "0,人1995年1月1日生(満24\r",
      "\r\n",
      "0,1995年1月1日生(満24歳\r",
      "\r\n",
      "0,995年1月1日生(満24歳)\r",
      "\r\n",
      "0,95年1月1日生(満24歳)男\r",
      "\r\n",
      "1,ふりがなさとういちろう名前秋山\r",
      "\r\n",
      "1,りがなさとういちろう名前秋山康\r",
      "\r\n",
      "1,がなさとういちろう名前秋山康之\r",
      "\r\n",
      "1,なさとういちろう名前秋山康之進\r",
      "\r\n",
      "1,さとういちろう名前秋山康之進1\r",
      "\r\n",
      "1,とういちろう名前秋山康之進19\r",
      "\r\n",
      "1,ういちろう名前秋山康之進199\r",
      "\r\n",
      "1,いちろう名前秋山康之進1995\r",
      "\r\n",
      "1,ちろう名前秋山康之進1995年\r",
      "\r\n",
      "1,ろう名前秋山康之進1995年1\r",
      "\r\n",
      "1,う名前秋山康之進1995年1月\r",
      "\r\n",
      "1,名前秋山康之進1995年1月1\r",
      "\r\n",
      "1,前秋山康之進1995年1月1日\r",
      "\r\n",
      "1,秋山康之進1995年1月1日生\r",
      "\r\n",
      "1,山康之進1995年1月1日生(\r",
      "\r\n",
      "1,康之進1995年1月1日生(満\r",
      "\r\n",
      "1,之進1995年1月1日生(満2\r",
      "\r\n",
      "1,進1995年1月1日生(満24\r",
      "\r\n",
      "1,1995年1月1日生(満24歳\r",
      "\r\n",
      "1,995年1月1日生(満24歳)\r",
      "\r\n",
      "1,95年1月1日生(満24歳)男\r",
      "\r\n",
      "2,ふりがなさとういちろう名前青木\r",
      "\r\n",
      "2,りがなさとういちろう名前青木恵\r",
      "\r\n",
      "2,がなさとういちろう名前青木恵哉\r",
      "\r\n",
      "2,なさとういちろう名前青木恵哉1\r",
      "\r\n",
      "2,さとういちろう名前青木恵哉19\r",
      "\r\n",
      "2,とういちろう名前青木恵哉199\r",
      "\r\n",
      "2,ういちろう名前青木恵哉1995\r",
      "\r\n",
      "2,いちろう名前青木恵哉1995年\r",
      "\r\n",
      "2,ちろう名前青木恵哉1995年1\r",
      "\r\n",
      "2,ろう名前青木恵哉1995年1月\r",
      "\r\n",
      "2,う名前青木恵哉1995年1月1\r",
      "\r\n",
      "2,名前青木恵哉1995年1月1日\r",
      "\r\n",
      "2,前青木恵哉1995年1月1日生\r",
      "\r\n",
      "2,青木恵哉1995年1月1日生(\r",
      "\r\n",
      "2,木恵哉1995年1月1日生(満\r",
      "\r\n",
      "2,恵哉1995年1月1日生(満2\r",
      "\r\n",
      "2,哉1995年1月1日生(満24\r",
      "\r\n",
      "2,1995年1月1日生(満24歳\r",
      "\r\n",
      "2,995年1月1日生(満24歳)\r",
      "\r\n",
      "2,95年1月1日生(満24歳)男\r",
      "\r\n",
      "3,ふりがなさとういちろう名前暁烏\r",
      "\r\n",
      "3,りがなさとういちろう名前暁烏敏\r",
      "\r\n",
      "3,がなさとういちろう名前暁烏敏1\r",
      "\r\n",
      "3,なさとういちろう名前暁烏敏19\r",
      "\r\n",
      "3,さとういちろう名前暁烏敏199\r",
      "\r\n",
      "3,とういちろう名前暁烏敏1995\r",
      "\r\n",
      "3,ういちろう名前暁烏敏1995年\r",
      "\r\n",
      "3,いちろう名前暁烏敏1995年1\r",
      "\r\n",
      "3,ちろう名前暁烏敏1995年1月\r",
      "\r\n",
      "3,ろう名前暁烏敏1995年1月1\r",
      "\r\n",
      "3,う名前暁烏敏1995年1月1日\r",
      "\r\n",
      "3,名前暁烏敏1995年1月1日生\r",
      "\r\n",
      "3,前暁烏敏1995年1月1日生(\r",
      "\r\n",
      "3,暁烏敏1995年1月1日生(満\r",
      "\r\n",
      "3,烏敏1995年1月1日生(満2\r",
      "\r\n",
      "3,敏1995年1月1日生(満24\r",
      "\r\n",
      "3,1995年1月1日生(満24歳\r",
      "\r\n",
      "3,995年1月1日生(満24歳)\r",
      "\r\n",
      "3,95年1月1日生(満24歳)男\r",
      "\r\n",
      "4,ふりがなさとういちろう名前明石\r",
      "\r\n",
      "4,りがなさとういちろう名前明石海\r",
      "\r\n",
      "4,がなさとういちろう名前明石海人\r",
      "\r\n",
      "4,なさとういちろう名前明石海人1\r",
      "\r\n",
      "4,さとういちろう名前明石海人19\r",
      "\r\n",
      "4,とういちろう名前明石海人199\r",
      "\r\n",
      "4,ういちろう名前明石海人1995\r",
      "\r\n",
      "4,いちろう名前明石海人1995年\r",
      "\r\n",
      "4,ちろう名前明石海人1995年1\r",
      "\r\n",
      "4,ろう名前明石海人1995年1月\r",
      "\r\n",
      "4,う名前明石海人1995年1月1\r",
      "\r\n",
      "4,名前明石海人1995年1月1日\r",
      "\r\n",
      "4,前明石海人1995年1月1日生\r",
      "\r\n",
      "4,明石海人1995年1月1日生(\r",
      "\r\n",
      "4,石海人1995年1月1日生(満\r",
      "\r\n",
      "4,海人1995年1月1日生(満2\r",
      "\r\n",
      "4,人1995年1月1日生(満24\r",
      "\r\n",
      "4,1995年1月1日生(満24歳\r",
      "\r\n",
      "4,995年1月1日生(満24歳)\r",
      "\r\n",
      "4,95年1月1日生(満24歳)男\r",
      "\r\n",
      "5,ふりがなさとういちろう名前麻生\r",
      "\r\n",
      "5,りがなさとういちろう名前麻生豊\r",
      "\r\n",
      "5,がなさとういちろう名前麻生豊1\r",
      "\r\n",
      "5,なさとういちろう名前麻生豊19\r",
      "\r\n",
      "5,さとういちろう名前麻生豊199\r",
      "\r\n",
      "5,とういちろう名前麻生豊1995\r",
      "\r\n",
      "5,ういちろう名前麻生豊1995年\r",
      "\r\n",
      "5,いちろう名前麻生豊1995年1\r",
      "\r\n",
      "5,ちろう名前麻生豊1995年1月\r",
      "\r\n",
      "5,ろう名前麻生豊1995年1月1\r",
      "\r\n",
      "5,う名前麻生豊1995年1月1日\r",
      "\r\n",
      "5,名前麻生豊1995年1月1日生\r",
      "\r\n",
      "5,前麻生豊1995年1月1日生(\r",
      "\r\n",
      "5,麻生豊1995年1月1日生(満\r",
      "\r\n",
      "5,生豊1995年1月1日生(満2\r",
      "\r\n",
      "5,豊1995年1月1日生(満24\r",
      "\r\n",
      "5,1995年1月1日生(満24歳\r",
      "\r\n",
      "5,995年1月1日生(満24歳)\r",
      "\r\n",
      "5,95年1月1日生(満24歳)男\r",
      "\r\n",
      "6,ふりがなさとういちろう名前青柳\r",
      "\r\n",
      "6,りがなさとういちろう名前青柳文\r",
      "\r\n",
      "6,がなさとういちろう名前青柳文蔵\r",
      "\r\n",
      "6,なさとういちろう名前青柳文蔵1\r",
      "\r\n",
      "6,さとういちろう名前青柳文蔵19\r",
      "\r\n",
      "6,とういちろう名前青柳文蔵199\r",
      "\r\n",
      "6,ういちろう名前青柳文蔵1995\r",
      "\r\n",
      "6,いちろう名前青柳文蔵1995年\r",
      "\r\n",
      "6,ちろう名前青柳文蔵1995年1\r",
      "\r\n",
      "6,ろう名前青柳文蔵1995年1月\r",
      "\r\n",
      "6,う名前青柳文蔵1995年1月1\r",
      "\r\n",
      "6,名前青柳文蔵1995年1月1日\r",
      "\r\n",
      "6,前青柳文蔵1995年1月1日生\r",
      "\r\n",
      "6,青柳文蔵1995年1月1日生(\r",
      "\r\n",
      "6,柳文蔵1995年1月1日生(満\r",
      "\r\n",
      "6,文蔵1995年1月1日生(満2\r",
      "\r\n",
      "6,蔵1995年1月1日生(満24\r",
      "\r\n",
      "6,1995年1月1日生(満24歳\r",
      "\r\n",
      "6,995年1月1日生(満24歳)\r",
      "\r\n",
      "6,95年1月1日生(満24歳)男\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!cat training_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['明石海人', '秋山康之進', '青木恵哉', '暁烏敏', '明石海人', '麻生豊', '青柳文蔵']"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回答データの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "明石海人\r",
      "\r\n",
      "秋山康之進\r",
      "\r\n",
      "青木恵哉\r",
      "\r\n",
      "暁烏敏\r",
      "\r\n",
      "明石海人\r",
      "\r\n",
      "麻生豊\r",
      "\r\n",
      "青柳文蔵\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "name_list = [[n] for n in name_list]\n",
    "\n",
    "with open(\"replies.csv\", \"w\", newline='') as f:\n",
    "    w = csv.writer(f, delimiter=\",\")\n",
    "    for  data_list in name_list:\n",
    "        w.writerow(data_list)\n",
    "        \n",
    "        \n",
    "!cat replies.csv       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn によるngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer = 'char', ngram_range=(3,3))\n",
    "vectorizer.fit(t_p)\n",
    "bow = vectorizer.transform(t_p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0]\n",
      " [1 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0]\n",
      " [1 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1]\n",
      " [1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(bow.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'う名前': 0,\n",
       " '名前明': 9,\n",
       " '前明石': 3,\n",
       " '明石海': 20,\n",
       " '石海人': 27,\n",
       " '海人1': 24,\n",
       " '人19': 2,\n",
       " '名前秋': 11,\n",
       " '前秋山': 5,\n",
       " '秋山康': 28,\n",
       " '山康之': 15,\n",
       " '康之進': 16,\n",
       " '之進1': 1,\n",
       " '進19': 31,\n",
       " '名前青': 12,\n",
       " '前青木': 6,\n",
       " '青木恵': 32,\n",
       " '木恵哉': 22,\n",
       " '恵哉1': 17,\n",
       " '哉19': 14,\n",
       " '名前暁': 10,\n",
       " '前暁烏': 4,\n",
       " '暁烏敏': 21,\n",
       " '烏敏1': 25,\n",
       " '敏19': 18,\n",
       " '名前麻': 13,\n",
       " '前麻生': 8,\n",
       " '麻生豊': 34,\n",
       " '生豊1': 26,\n",
       " '豊19': 30,\n",
       " '前青柳': 7,\n",
       " '青柳文': 33,\n",
       " '柳文蔵': 23,\n",
       " '文蔵1': 19,\n",
       " '蔵19': 29}"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 名字と名前のベクトル化：BoW（Bag of words）\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MeCab\n",
    "tagger = MeCab.Tagger()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    node = tagger.parseToNode(text)\n",
    "    tokens = []\n",
    "    while node:\n",
    "        if node.surface != '':\n",
    "            tokens.append(node.surface)\n",
    "        node = node.next\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    '私は私のことが好きなあなたが好きです',\n",
    "    '私はラーメンが好きです',\n",
    "    '富士山は日本一高い山です',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(tokenizer = tokenize)\n",
    "vectorizer.fit(name_list)\n",
    "bow = vectorizer.transform(name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (7, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>哉</th>\n",
       "      <th>康之</th>\n",
       "      <th>恵</th>\n",
       "      <th>文蔵</th>\n",
       "      <th>明石</th>\n",
       "      <th>暁烏敏</th>\n",
       "      <th>海人</th>\n",
       "      <th>秋山</th>\n",
       "      <th>豊</th>\n",
       "      <th>進</th>\n",
       "      <th>青木</th>\n",
       "      <th>青柳</th>\n",
       "      <th>麻生</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   哉  康之  恵  文蔵  明石  暁烏敏  海人  秋山  豊  進  青木  青柳  麻生\n",
       "0  0   0  0   0   1    0   1   0  0  0   0   0   0\n",
       "1  0   1  0   0   0    0   0   1  0  1   0   0   0\n",
       "2  1   0  1   0   0    0   0   0  0  0   1   0   0\n",
       "3  0   0  0   0   0    1   0   0  0  0   0   0   0\n",
       "4  0   0  0   0   1    0   1   0  0  0   0   0   0\n",
       "5  0   0  0   0   0    0   0   0  1  0   0   0   1\n",
       "6  0   0  0   1   0    0   0   0  0  0   0   1   0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "bow_table = pd.DataFrame(bow.toarray(), columns=vectorizer.get_feature_names())\n",
    "print('Shape: {}'.format(bow.shape))\n",
    "bow_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Collecting torch\n",
      "  Downloading torch-1.4.0-cp37-cp37m-manylinux1_x86_64.whl (753.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 753.4 MB 5.9 MB/s eta 0:00:012   |▋                               | 13.9 MB 3.7 MB/s eta 0:03:20     |█▉                              | 41.9 MB 8.2 MB/s eta 0:01:27     |███▎                            | 75.9 MB 3.9 MB/s eta 0:02:56     |███▋                            | 84.4 MB 5.7 MB/s eta 0:01:58     |████                            | 92.1 MB 4.9 MB/s eta 0:02:16     |████▏                           | 99.1 MB 7.1 MB/s eta 0:01:32     |█████                           | 115.5 MB 5.9 MB/s eta 0:01:48     |█████▏                          | 120.6 MB 6.1 MB/s eta 0:01:44     |█████▋                          | 132.9 MB 9.9 MB/s eta 0:01:03     |█████▊                          | 133.9 MB 9.9 MB/s eta 0:01:03     |██████▋                         | 156.1 MB 4.1 MB/s eta 0:02:27     |██████▉                         | 161.5 MB 5.7 MB/s eta 0:01:45     |██████▉                         | 162.0 MB 5.7 MB/s eta 0:01:45     |████████                        | 189.0 MB 10.9 MB/s eta 0:00:52     |████████▏                       | 191.5 MB 5.7 MB/s eta 0:01:39     |████████▍                       | 198.6 MB 5.9 MB/s eta 0:01:35     |████████▉                       | 207.0 MB 5.4 MB/s eta 0:01:41     |████████▉                       | 208.3 MB 3.6 MB/s eta 0:02:33     |█████████                       | 210.6 MB 3.6 MB/s eta 0:02:32     |█████████                       | 210.9 MB 3.6 MB/s eta 0:02:32     |█████████                       | 214.1 MB 3.7 MB/s eta 0:02:26     |█████████▋                      | 226.8 MB 5.8 MB/s eta 0:01:32     |█████████▉                      | 231.3 MB 3.9 MB/s eta 0:02:13     |██████████                      | 237.7 MB 3.3 MB/s eta 0:02:36     |██████████▏                     | 238.5 MB 3.3 MB/s eta 0:02:36     |██████████▎                     | 242.0 MB 7.5 MB/s eta 0:01:09     |██████████▎                     | 242.9 MB 7.5 MB/s eta 0:01:09     |███████████                     | 257.8 MB 6.7 MB/s eta 0:01:14     |███████████                     | 258.2 MB 6.7 MB/s eta 0:01:14     |███████████                     | 260.4 MB 6.7 MB/s eta 0:01:14     |███████████                     | 261.4 MB 6.7 MB/s eta 0:01:14     |███████████▍                    | 268.6 MB 5.5 MB/s eta 0:01:29     |████████████▎                   | 289.1 MB 12.3 MB/s eta 0:00:38     |████████████▌                   | 294.2 MB 12.3 MB/s eta 0:00:38     |████████████▌                   | 294.9 MB 12.3 MB/s eta 0:00:38     |████████████▊                   | 298.6 MB 6.0 MB/s eta 0:01:17     |████████████▊                   | 299.0 MB 6.0 MB/s eta 0:01:16     |████████████▊                   | 300.0 MB 6.0 MB/s eta 0:01:16     |████████████▉                   | 303.1 MB 6.8 MB/s eta 0:01:07     |█████████████                   | 303.5 MB 6.8 MB/s eta 0:01:07     |█████████████▏                  | 310.2 MB 6.8 MB/s eta 0:01:06     |█████████████▎                  | 311.3 MB 10.0 MB/s eta 0:00:45     |█████████████▎                  | 312.0 MB 10.0 MB/s eta 0:00:45     |█████████████▌                  | 318.0 MB 5.0 MB/s eta 0:01:27     |█████████████▊                  | 322.2 MB 5.0 MB/s eta 0:01:27     |██████████████▎                 | 337.3 MB 5.4 MB/s eta 0:01:17     |██████████████▍                 | 337.9 MB 5.4 MB/s eta 0:01:17     |██████████████▍                 | 338.9 MB 4.8 MB/s eta 0:01:26     |███████████████                 | 351.5 MB 3.7 MB/s eta 0:01:49     |███████████████                 | 352.9 MB 7.8 MB/s eta 0:00:52     |████████████████                | 374.8 MB 4.8 MB/s eta 0:01:19     |████████████████                | 375.9 MB 4.8 MB/s eta 0:01:19     |████████████████                | 376.1 MB 4.8 MB/s eta 0:01:19     |████████████████▋               | 391.7 MB 5.1 MB/s eta 0:01:12     |█████████████████▎              | 407.5 MB 5.3 MB/s eta 0:01:06     |█████████████████▎              | 407.8 MB 5.3 MB/s eta 0:01:06     |█████████████████▍              | 409.0 MB 5.3 MB/s eta 0:01:05     |█████████████████▋              | 413.5 MB 4.4 MB/s eta 0:01:19     |█████████████████▊              | 416.8 MB 4.4 MB/s eta 0:01:18     |█████████████████▊              | 417.1 MB 4.4 MB/s eta 0:01:18     |█████████████████▊              | 417.5 MB 7.5 MB/s eta 0:00:45     |██████████████████▌             | 436.2 MB 8.4 MB/s eta 0:00:38     |██████████████████▉             | 442.5 MB 6.9 MB/s eta 0:00:46     |████████████████████▉           | 490.7 MB 4.0 MB/s eta 0:01:06     |████████████████████▉           | 491.2 MB 4.0 MB/s eta 0:01:06     |█████████████████████           | 493.1 MB 4.0 MB/s eta 0:01:05     |█████████████████████▍          | 503.8 MB 2.6 MB/s eta 0:01:36     |█████████████████████▋          | 508.2 MB 4.8 MB/s eta 0:00:52     |██████████████████████▉         | 536.5 MB 7.9 MB/s eta 0:00:28     |███████████████████████▊        | 559.8 MB 15.9 MB/s eta 0:00:13     |████████████████████████        | 567.2 MB 6.8 MB/s eta 0:00:28     |█████████████████████████▎      | 595.7 MB 4.8 MB/s eta 0:00:33     |█████████████████████████▍      | 597.1 MB 4.8 MB/s eta 0:00:33     |█████████████████████████▌      | 600.5 MB 4.8 MB/s eta 0:00:32     |███████████████████████████▏    | 639.1 MB 4.8 MB/s eta 0:00:24     |███████████████████████████▎    | 641.6 MB 4.8 MB/s eta 0:00:24     |████████████████████████████▍   | 667.1 MB 2.3 MB/s eta 0:00:39     |██████████████████████████████  | 705.9 MB 5.8 MB/s eta 0:00:09     |██████████████████████████████  | 706.6 MB 5.8 MB/s eta 0:00:09     |██████████████████████████████▏ | 710.7 MB 5.8 MB/s eta 0:00:08     |███████████████████████████████▋| 745.1 MB 5.7 MB/s eta 0:00:02\n",
      "\u001b[?25hInstalling collected packages: torch\n",
      "Successfully installed torch-1.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7feac98a0f30>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n"
     ]
    }
   ],
   "source": [
    "# torch.tensor(data) creates a torch.Tensor object with the given data.\n",
    "V_data = [1., 2., 3.]\n",
    "V = torch.tensor(V_data)\n",
    "print(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "# Creates a matrix\n",
    "M_data = [[1., 2., 3.], [4., 5., 6]]\n",
    "M = torch.tensor(M_data)\n",
    "print(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 2.],\n",
      "         [3., 4.]],\n",
      "\n",
      "        [[5., 6.],\n",
      "         [7., 8.]]])\n"
     ]
    }
   ],
   "source": [
    "# Create a 3D tensor of size 2x2x2.\n",
    "T_data = [[[1., 2.], [3., 4.]],\n",
    "          [[5., 6.], [7., 8.]]]\n",
    "T = torch.tensor(T_data)\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.5256, -0.7502, -0.6540, -1.6095, -0.1002],\n",
      "         [-0.6092, -0.9798, -1.6091, -0.7121,  0.3037],\n",
      "         [-0.7773, -0.2515, -0.2223,  1.6871,  0.2284],\n",
      "         [ 0.4676, -0.6970, -1.1608,  0.6995,  0.1991]],\n",
      "\n",
      "        [[ 0.8657,  0.2444, -0.6629,  0.8073,  1.1017],\n",
      "         [-0.1759, -2.2456, -1.4465,  0.0612, -0.6177],\n",
      "         [-0.7981, -0.1316,  1.8793, -0.0721,  0.1578],\n",
      "         [-0.7735,  0.1991,  0.0457,  0.1530, -0.4757]],\n",
      "\n",
      "        [[-0.1110,  0.2927, -0.1578, -0.0288,  0.4533],\n",
      "         [ 1.1422,  0.2486, -1.7754, -0.0255, -1.0233],\n",
      "         [-0.5962, -1.0055,  0.4285,  1.4761, -1.7869],\n",
      "         [ 1.6103, -0.7040, -0.1853, -0.9962, -0.8313]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn((3, 4, 5))\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/deep_learning_nlp_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7feac98a0f30>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2879, 1.0579, 0.9621, 0.3935, 1.1322])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.randn(5)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2879, 1.0579, 0.9621, 0.3935, 1.1322])\n",
      "tensor([0.1168, 0.2523, 0.2293, 0.1298, 0.2718])\n",
      "tensor(1.)\n",
      "tensor([-2.1471, -1.3771, -1.4729, -2.0415, -1.3028])\n"
     ]
    }
   ],
   "source": [
    "print(data)\n",
    "print(F.softmax(data, dim=0))\n",
    "print(F.softmax(data, dim=0).sum())\n",
    "print(F.log_softmax(data, dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(\"me gusta comer en la cafeteria\".split(), \"SPANISH\"),\n",
    "        (\"Give it to me\".split(), \"ENGLISH\"),\n",
    "        (\"No creo que sea una buena idea\".split(), \"SPANISH\"),\n",
    "        (\"No it is not a good idea to get lost at sea\".split(), \"ENGLISH\")]\n",
    "\n",
    "test_data = [(\"Yo creo que si\".split(), \"SPANISH\"),\n",
    "             (\"it is lost on me\".split(), \"ENGLISH\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'me': 0, 'gusta': 1, 'comer': 2, 'en': 3, 'la': 4, 'cafeteria': 5, 'Give': 6, 'it': 7, 'to': 8, 'No': 9, 'creo': 10, 'que': 11, 'sea': 12, 'una': 13, 'buena': 14, 'idea': 15, 'is': 16, 'not': 17, 'a': 18, 'good': 19, 'get': 20, 'lost': 21, 'at': 22, 'Yo': 23, 'si': 24, 'on': 25}\n"
     ]
    }
   ],
   "source": [
    "word_to_ix = {}\n",
    "\n",
    "for sent, _ in data + test_data:\n",
    "    for word in sent:\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix)\n",
    "print(word_to_ix)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(word_to_ix)\n",
    "NUM_LABELS = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoWClassifier(nn.Module):  # inheriting from nn.Module!\n",
    "\n",
    "    def __init__(self, num_labels, vocab_size):\n",
    "        # calls the init function of nn.Module.  Dont get confused by syntax,\n",
    "        # just always do it in an nn.Module\n",
    "        super(BoWClassifier, self).__init__()\n",
    "\n",
    "        # Define the parameters that you will need.  In this case, we need A and b,\n",
    "        # the parameters of the affine mapping.\n",
    "        # Torch defines nn.Linear(), which provides the affine map.\n",
    "        # Make sure you understand why the input dimension is vocab_size\n",
    "        # and the output is num_labels!\n",
    "        self.linear = nn.Linear(vocab_size, num_labels)\n",
    "\n",
    "        # NOTE! The non-linearity log softmax does not have parameters! So we don't need\n",
    "        # to worry about that here\n",
    "\n",
    "    def forward(self, bow_vec):\n",
    "        # Pass the input through the linear layer,\n",
    "        # then pass that through log_softmax.\n",
    "        # Many non-linearities and other functions are in torch.nn.functional\n",
    "        return F.log_softmax(self.linear(bow_vec), dim=1)\n",
    "    \n",
    "def make_bow_vector(sentence, word_to_ix):\n",
    "    vec = torch.zeros(len(word_to_ix))\n",
    "    for word in sentence:\n",
    "        vec[word_to_ix[word]] += 1\n",
    "    return vec.view(1, -1)\n",
    "\n",
    "def make_target(label, label_to_ix):\n",
    "    return torch.LongTensor([label_to_ix[label]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0394,  0.0471, -0.1313, -0.0931,  0.0669,  0.0351, -0.0834, -0.0594,\n",
      "          0.1796, -0.0363,  0.1106,  0.0849, -0.1268, -0.1668,  0.1882,  0.0102,\n",
      "          0.1344,  0.0406,  0.0631,  0.1465,  0.1860, -0.1301,  0.0245,  0.1464,\n",
      "          0.1421,  0.1218],\n",
      "        [-0.1419, -0.1412, -0.1186,  0.0246,  0.1955, -0.1239,  0.1045, -0.1085,\n",
      "         -0.1844, -0.0417,  0.1130,  0.1821, -0.1218,  0.0426,  0.1692,  0.1300,\n",
      "          0.1222,  0.1394,  0.1240,  0.0507, -0.1341, -0.1647, -0.0899, -0.0228,\n",
      "         -0.1202,  0.0717]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0607, -0.0444], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "model = BoWClassifier(NUM_LABELS, VOCAB_SIZE)\n",
    "\n",
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['me', 'gusta', 'comer', 'en', 'la', 'cafeteria'], 'SPANISH')\n",
      "tensor([[1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[-0.0103, -4.5792]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    sample = data[0]\n",
    "    print(sample)\n",
    "    bow_vector = make_bow_vector(sample[0], word_to_ix)\n",
    "    print(bow_vector)\n",
    "    log_probs = model(bow_vector)\n",
    "    print(log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_ix = {\"SPANISH\": 0, \"ENGLISH\": 1}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "では、訓練しましょう。これを行うには、インスタンスを渡して対数確率を取得し、損失関数を計算し、損失関数の勾配を計算し、勾配ステップでパラメータを更新します。損失関数は Torch が nn パッケージで提供しています。 nn.NLLLoss() は、我々が求める負の対数尤度損失です。また、最適化関数も torch.optim で定義されています。ここではSGDを使用します。\n",
    "\n",
    "NLLLossへの入力は対数確率のベクトルとターゲットラベルであることに注意してください。NLLLoss は対数確率を計算してくれません。これが、ネットワークの最後の層が log softmax である理由です。損失関数 nn.CrossEntropyLoss() は NLLLoss() と同じですが、log softmax を計算してくれる点を除けば、NLLLoss() と同じです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0654, -2.7602]])\n",
      "tensor([[-3.0735, -0.0474]])\n",
      "tensor([ 0.6468, -0.4232], grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Run on test data before we train, just to see a before-and-after\n",
    "with torch.no_grad():\n",
    "    for instance, label in test_data:\n",
    "        bow_vec = make_bow_vector(instance, word_to_ix)\n",
    "        log_probs = model(bow_vec)\n",
    "        print(log_probs)\n",
    "\n",
    "# Print the matrix column corresponding to \"creo\"\n",
    "print(next(model.parameters())[:, word_to_ix[\"creo\"]])\n",
    "\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0562, -2.9067]])\n",
      "tensor([[-3.2892, -0.0380]])\n",
      "tensor([ 0.6826, -0.4590], grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 通常、学習データを何度か通過させたいと思うでしょう。100は実際のデータセットよりもはるかに大きいですが、実際のデータセットでは2つのインスタンスを使用します。 通常、5～30エポックの間のどこかが妥当です。\n",
    "# Usually you want to pass over the training data several times.\n",
    "# 100 is much bigger than on a real data set, but real datasets have more than\n",
    "# two instances.  Usually, somewhere between 5 and 30 epochs is reasonable.\n",
    "for epoch in range(100):\n",
    "    for instance, label in data:\n",
    "        # Step 1. Remember that PyTorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 2. Make our BOW vector and also we must wrap the target in a\n",
    "        # Tensor as an integer. For example, if the target is SPANISH, then\n",
    "        # we wrap the integer 0. The loss function then knows that the 0th\n",
    "        # element of the log probabilities is the log probability\n",
    "        # corresponding to SPANISH\n",
    "        bow_vec = make_bow_vector(instance, word_to_ix)\n",
    "        target = make_target(label, label_to_ix)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        log_probs = model(bow_vec)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        # calling optimizer.step()\n",
    "        loss = loss_function(log_probs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for instance, label in test_data:\n",
    "        bow_vec = make_bow_vector(instance, word_to_ix)\n",
    "        log_probs = model(bow_vec)\n",
    "        print(log_probs)\n",
    "\n",
    "# Index corresponding to Spanish goes up, English goes down!\n",
    "print(next(model.parameters())[:, word_to_ix[\"creo\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0562, -2.9067]], grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([[-3.2892, -0.0380]], grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([ 0.6826, -0.4590], grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "with torch.enable_grad():\n",
    "    \n",
    "    for instance, label in test_data:\n",
    "        bow_vec = make_bow_vector(instance, word_to_ix)\n",
    "        log_probs = model(bow_vec)\n",
    "        print(log_probs)\n",
    "\n",
    "# Index corresponding to Spanish goes up, English goes down!\n",
    "print(next(model.parameters())[:, word_to_ix[\"creo\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      "data: 1.0\n",
      "requires_grad: True\n",
      "grad: None\n",
      "grad_fn: None\n",
      "is_leaf: True\n",
      "\n",
      "y\n",
      "data: 2.0\n",
      "requires_grad: False\n",
      "grad: None\n",
      "grad_fn: None\n",
      "is_leaf: True\n",
      "\n",
      "z\n",
      "data: 2.0\n",
      "requires_grad: True\n",
      "grad: None\n",
      "grad_fn: <MulBackward0 object at 0x7fea7cffc410>\n",
      "is_leaf: False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Creating the graph\n",
    "x = torch.tensor(1.0, requires_grad = True)\n",
    "y = torch.tensor(2.0)\n",
    "z = x * y\n",
    "\n",
    "# Displaying\n",
    "for i, name in zip([x, y, z], \"xyz\"):\n",
    "    print(f\"{name}\\ndata: {i.data}\\nrequires_grad: {i.requires_grad}\\n\\\n",
    "grad: {i.grad}\\ngrad_fn: {i.grad_fn}\\nis_leaf: {i.is_leaf}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP_studyのやつパクリ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "暁烏敏\n",
      "りがなさとういちろう名前青柳文蔵1995\n",
      "AI reply: 青柳文蔵\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 813\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    814\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-576-d167aad38614>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0minput_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdialogue_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mpredicted_class_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    857\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         )\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from os.path import dirname, join, normpath\n",
    "\n",
    "import MeCab\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "class DialogueAgent:\n",
    "    def __init__(self):\n",
    "        self.tagger = MeCab.Tagger()\n",
    "\n",
    "    def _tokenize(self, text): # 形態素解析\n",
    "        node = self.tagger.parseToNode(text)\n",
    "\n",
    "        tokens = []\n",
    "        while node:\n",
    "            if node.surface != '':\n",
    "                tokens.append(node.surface)\n",
    " \n",
    "            node = node.next\n",
    "        return tokens\n",
    "\n",
    "    def train(self, texts, labels): # 2. 文章とラベルからニューラルネットワークを更新\n",
    "        pipeline = Pipeline([\n",
    "            ('vecttorizer', CountVectorizer(tokenizer=self._tokenize)), \n",
    "            ('classifier', SVC()),\n",
    "        ])\n",
    "        pipeline.fit(texts, labels)\n",
    "        self.pipeline = pipeline\n",
    "\n",
    "    def predict(self, texts): # 3. 他の文章でのニューロンの反応をチェック\n",
    "        return self.pipeline.predict(texts)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    BASE_DIR = normpath(dirname('__file__'))\n",
    "\n",
    "    training_data = pd.read_csv(join(BASE_DIR, './training_data.csv'))  # 学習用読み込み文章\n",
    "\n",
    "    dialogue_agent = DialogueAgent()\n",
    "    dialogue_agent.train(training_data['text'], training_data['label']) # 学習用読み込み文章とラベルの組を学習\n",
    "\n",
    "    with open(join(BASE_DIR, './replies.csv')) as f:  # 応答文章\n",
    "        replies = f.read().split('\\n')\n",
    "\n",
    "    input_text = '名前を教えてよ'\n",
    "    predictions = dialogue_agent.predict([input_text]) \n",
    "    predicted_class_id = predictions[0]  \n",
    "\n",
    "    print(replies[predicted_class_id])\n",
    "\n",
    "    while True:\n",
    "        input_text = input()\n",
    "        predictions = dialogue_agent.predict([input_text])\n",
    "        predicted_class_id = predictions[0]\n",
    "\n",
    "        print('AI reply: ' + replies[predicted_class_id])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自作検索関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.find('固有名詞', 0, 100)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 7)"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# reモジュールをインポート\n",
    "import re\n",
    "\n",
    "# 'two'にマッチした結果をマッチオブジェクトで返す\n",
    "re.search(r'two', s).span()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 3)"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# span()メソッドを使うと、位置が返ります。\n",
    "re.search(r'\\w{3}', s).span()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 7]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_L = [500,0,0,0,0,0,0,500,200]\n",
    "index_num = [n for n, v in enumerate(test_L) if v == 500]\n",
    "print(index_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.find('two')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.find('two', 5)\n",
    "\n",
    "\n",
    "'two' in s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def pull_out(text, word, buffer):\n",
    "    num = 0\n",
    "    for i in range(len(text)):\n",
    "        evalu = word in text[num:]\n",
    "        if  evalu == True:\n",
    "            num = text.find(word, num+1)\n",
    "            print(text[num-buffer:num+buffer])                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytext = '履歴書2019年12月25日現在ふりがなさとういちろう名前青柳文蔵1995年1月1日生(満24歳)男・女ふりがなとうきょうとちよだくさざんたわー電話000-0000-0000emailtest1@sample.comふりがな電話email年月学歴・職歴学歴20104東京都砂糖高等学校入学20133東京都砂糖高等学校卒業20134東京都菓子大学入学20173東京都菓子大学卒業職歴201710donuts株式会社入社現在に至る以上現住所〒100-0000東京都千代田区サザンタワー現住所〒(現住所以外に連絡を希望する場合のみ入力)証明写真縦36mm40mm横24mm30mm本人単身胸から上裏面のりづけ年・2年・2年月学歴・職歴年月免許・資格201212toeic公開テスト800点取得志望動機・特技・アピールポイントなどdonutsは、サービスやゲームにおいて1年、2年で終わってしまうようなものではなく、世の中に何らかの価値をもたらし、100年先にもその価値が残り続けるものを目指してプロダクト創りをしています。そのために社会や時流に変化をもたらすもの創り出していこうという想いを込めてサービスを作り出しています。通勤時間電車約1時間00分扶養家族数(配偶者を除く)0人配偶者有・無配偶者の扶養義務有・無本人希望欄(特に給料・職種・勤務時間・勤務地・その他について希望があれば記入)donutsは、サービスやゲームにおいて1年、2年で終わってしまうようなものではなく、世の中に何らかの価値をもたらし、100年先にもその価値が残り続けるものを目指してプロダクト創りをしています。そのために社会や時流に変化をもたらすもの創り出していこうという想いを込めてサービスを作り出しています。 '\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "履歴\t名詞,一般,*,*,*,*,履歴,リレキ,リレキ\n",
      "書\t名詞,接尾,一般,*,*,*,書,ショ,ショ\n",
      "2019\t名詞,数,*,*,*,*,*\n",
      "年\t名詞,接尾,助数詞,*,*,*,年,ネン,ネン\n",
      "12\t名詞,数,*,*,*,*,*\n",
      "月\t名詞,一般,*,*,*,*,月,ツキ,ツキ\n",
      "25\t名詞,数,*,*,*,*,*\n",
      "日\t名詞,接尾,助数詞,*,*,*,日,ニチ,ニチ\n",
      "現在\t名詞,副詞可能,*,*,*,*,現在,ゲンザイ,ゲンザイ\n",
      "ふりがな\t名詞,一般,*,*,*,*,ふりがな,フリガナ,フリガナ\n",
      "さとう\t形容詞,自立,*,*,形容詞・アウオ段,連用ゴザイ接続,さとい,サトウ,サトー\n",
      "いちろう\t名詞,固有名詞,人名,名,*,*,いちろう,イチロウ,イチロー\n",
      "名前\t名詞,一般,*,*,*,*,名前,ナマエ,ナマエ\n",
      "青柳\t名詞,一般,*,*,*,*,青柳,アオヤギ,アオヤギ\n",
      "文蔵\t名詞,固有名詞,地域,一般,*,*,文蔵,ブゾウ,ブゾー\n",
      "1995\t名詞,数,*,*,*,*,*\n",
      "年\t名詞,接尾,助数詞,*,*,*,年,ネン,ネン\n",
      "1\t名詞,数,*,*,*,*,*\n",
      "月\t名詞,一般,*,*,*,*,月,ツキ,ツキ\n",
      "1\t名詞,数,*,*,*,*,*\n",
      "日生\t名詞,固有名詞,組織,*,*,*,日生,ニッセイ,ニッセイ\n",
      "(\t名詞,サ変接続,*,*,*,*,*\n",
      "満\t接頭詞,数接続,*,*,*,*,満,マン,マン\n",
      "24\t名詞,数,*,*,*,*,*\n",
      "歳\t名詞,接尾,助数詞,*,*,*,歳,サイ,サイ\n",
      ")\t名詞,サ変接続,*,*,*,*,*\n",
      "男\t名詞,一般,*,*,*,*,男,オトコ,オトコ\n",
      "・\t記号,一般,*,*,*,*,・,・,・\n",
      "女\t名詞,一般,*,*,*,*,女,オンナ,オンナ\n",
      "ふりがな\t名詞,一般,*,*,*,*,ふりがな,フリガナ,フリガナ\n",
      "とうき\t名詞,一般,*,*,*,*,とうき,トウキ,トーキ\n",
      "ょうとちよだくさざんたわ\t名詞,一般,*,*,*,*,*\n",
      "ー\t名詞,一般,*,*,*,*,*\n",
      "電話\t名詞,サ変接続,*,*,*,*,電話,デンワ,デンワ\n",
      "000\t名詞,数,*,*,*,*,*\n",
      "-\t名詞,サ変接続,*,*,*,*,*\n",
      "0000\t名詞,数,*,*,*,*,*\n",
      "-\t名詞,サ変接続,*,*,*,*,*\n",
      "0000\t名詞,数,*,*,*,*,*\n",
      "emailtest\t名詞,一般,*,*,*,*,*\n",
      "1\t名詞,数,*,*,*,*,*\n",
      "@\t名詞,サ変接続,*,*,*,*,*\n",
      "sample\t名詞,一般,*,*,*,*,*\n",
      ".\t名詞,サ変接続,*,*,*,*,*\n",
      "com\t名詞,一般,*,*,*,*,*\n",
      "ふりがな\t名詞,一般,*,*,*,*,ふりがな,フリガナ,フリガナ\n",
      "電話\t名詞,サ変接続,*,*,*,*,電話,デンワ,デンワ\n",
      "email\t名詞,一般,*,*,*,*,*\n",
      "年月\t名詞,一般,*,*,*,*,年月,トシツキ,トシツキ\n",
      "学歴\t名詞,一般,*,*,*,*,学歴,ガクレキ,ガクレキ\n",
      "・\t記号,一般,*,*,*,*,・,・,・\n",
      "職歴\t名詞,一般,*,*,*,*,職歴,ショクレキ,ショクレキ\n",
      "学歴\t名詞,一般,*,*,*,*,学歴,ガクレキ,ガクレキ\n",
      "20104\t名詞,数,*,*,*,*,*\n",
      "東京\t名詞,固有名詞,地域,一般,*,*,東京,トウキョウ,トーキョー\n",
      "都\t名詞,接尾,地域,*,*,*,都,ト,ト\n",
      "砂糖\t名詞,一般,*,*,*,*,砂糖,サトウ,サトー\n",
      "高等\t名詞,形容動詞語幹,*,*,*,*,高等,コウトウ,コートー\n",
      "学校\t名詞,一般,*,*,*,*,学校,ガッコウ,ガッコー\n",
      "入学\t名詞,サ変接続,*,*,*,*,入学,ニュウガク,ニューガク\n",
      "20133\t名詞,数,*,*,*,*,*\n",
      "東京\t名詞,固有名詞,地域,一般,*,*,東京,トウキョウ,トーキョー\n",
      "都\t名詞,接尾,地域,*,*,*,都,ト,ト\n",
      "砂糖\t名詞,一般,*,*,*,*,砂糖,サトウ,サトー\n",
      "高等\t名詞,形容動詞語幹,*,*,*,*,高等,コウトウ,コートー\n",
      "学校\t名詞,一般,*,*,*,*,学校,ガッコウ,ガッコー\n",
      "卒業\t名詞,サ変接続,*,*,*,*,卒業,ソツギョウ,ソツギョー\n",
      "20134\t名詞,数,*,*,*,*,*\n",
      "東京\t名詞,固有名詞,地域,一般,*,*,東京,トウキョウ,トーキョー\n",
      "都\t名詞,接尾,地域,*,*,*,都,ト,ト\n",
      "菓子\t名詞,一般,*,*,*,*,菓子,カシ,カシ\n",
      "大学\t名詞,一般,*,*,*,*,大学,ダイガク,ダイガク\n",
      "入学\t名詞,サ変接続,*,*,*,*,入学,ニュウガク,ニューガク\n",
      "20173\t名詞,数,*,*,*,*,*\n",
      "東京\t名詞,固有名詞,地域,一般,*,*,東京,トウキョウ,トーキョー\n",
      "都\t名詞,接尾,地域,*,*,*,都,ト,ト\n",
      "菓子\t名詞,一般,*,*,*,*,菓子,カシ,カシ\n",
      "大学\t名詞,一般,*,*,*,*,大学,ダイガク,ダイガク\n",
      "卒業\t名詞,サ変接続,*,*,*,*,卒業,ソツギョウ,ソツギョー\n",
      "職歴\t名詞,一般,*,*,*,*,職歴,ショクレキ,ショクレキ\n",
      "201710\t名詞,数,*,*,*,*,*\n",
      "donuts\t名詞,一般,*,*,*,*,*\n",
      "株式会社\t名詞,一般,*,*,*,*,株式会社,カブシキガイシャ,カブシキガイシャ\n",
      "入社\t名詞,サ変接続,*,*,*,*,入社,ニュウシャ,ニューシャ\n",
      "現在\t名詞,副詞可能,*,*,*,*,現在,ゲンザイ,ゲンザイ\n",
      "に\t助詞,格助詞,一般,*,*,*,に,ニ,ニ\n",
      "至る\t動詞,自立,*,*,五段・ラ行,基本形,至る,イタル,イタル\n",
      "以上\t名詞,非自立,副詞可能,*,*,*,以上,イジョウ,イジョー\n",
      "現住\t名詞,サ変接続,*,*,*,*,現住,ゲンジュウ,ゲンジュー\n",
      "所\t名詞,接尾,一般,*,*,*,所,ショ,ショ\n",
      "〒\t記号,一般,*,*,*,*,〒,ユウビンバンゴウ,ユービンバンゴー\n",
      "100\t名詞,数,*,*,*,*,*\n",
      "-\t名詞,サ変接続,*,*,*,*,*\n",
      "0000\t名詞,数,*,*,*,*,*\n",
      "東京\t名詞,固有名詞,地域,一般,*,*,東京,トウキョウ,トーキョー\n",
      "都\t名詞,接尾,地域,*,*,*,都,ト,ト\n",
      "千代田\t名詞,固有名詞,地域,一般,*,*,千代田,チヨダ,チヨダ\n",
      "区\t名詞,接尾,地域,*,*,*,区,ク,ク\n",
      "サザンタワー\t名詞,固有名詞,一般,*,*,*,*\n",
      "現住所\t名詞,一般,*,*,*,*,現住所,ゲンジュウショ,ゲンジューショ\n",
      "〒(\t名詞,サ変接続,*,*,*,*,*\n",
      "現住\t名詞,サ変接続,*,*,*,*,現住,ゲンジュウ,ゲンジュー\n",
      "所\t名詞,接尾,一般,*,*,*,所,ショ,ショ\n",
      "以外\t名詞,非自立,副詞可能,*,*,*,以外,イガイ,イガイ\n",
      "に\t助詞,格助詞,一般,*,*,*,に,ニ,ニ\n",
      "連絡\t名詞,サ変接続,*,*,*,*,連絡,レンラク,レンラク\n",
      "を\t助詞,格助詞,一般,*,*,*,を,ヲ,ヲ\n",
      "希望\t名詞,サ変接続,*,*,*,*,希望,キボウ,キボー\n",
      "する\t動詞,自立,*,*,サ変・スル,基本形,する,スル,スル\n",
      "場合\t名詞,副詞可能,*,*,*,*,場合,バアイ,バアイ\n",
      "のみ\t助詞,副助詞,*,*,*,*,のみ,ノミ,ノミ\n",
      "入力\t名詞,サ変接続,*,*,*,*,入力,ニュウリョク,ニューリョク\n",
      ")\t名詞,サ変接続,*,*,*,*,*\n",
      "証明\t名詞,サ変接続,*,*,*,*,証明,ショウメイ,ショーメイ\n",
      "写真\t名詞,一般,*,*,*,*,写真,シャシン,シャシン\n",
      "縦\t名詞,一般,*,*,*,*,縦,タテ,タテ\n",
      "36\t名詞,数,*,*,*,*,*\n",
      "mm\t名詞,一般,*,*,*,*,*\n",
      "40\t名詞,数,*,*,*,*,*\n",
      "mm\t名詞,一般,*,*,*,*,*\n",
      "横\t名詞,一般,*,*,*,*,横,ヨコ,ヨコ\n",
      "24\t名詞,数,*,*,*,*,*\n",
      "mm\t名詞,一般,*,*,*,*,*\n",
      "30\t名詞,数,*,*,*,*,*\n",
      "mm\t名詞,一般,*,*,*,*,*\n",
      "本人\t名詞,一般,*,*,*,*,本人,ホンニン,ホンニン\n",
      "単身\t名詞,一般,*,*,*,*,単身,タンシン,タンシン\n",
      "胸\t名詞,一般,*,*,*,*,胸,ムネ,ムネ\n",
      "から\t助詞,格助詞,一般,*,*,*,から,カラ,カラ\n",
      "上\t名詞,一般,*,*,*,*,上,ウエ,ウエ\n",
      "裏面\t名詞,一般,*,*,*,*,裏面,リメン,リメン\n",
      "のり\t動詞,自立,*,*,五段・ラ行,連用形,のる,ノリ,ノリ\n",
      "づけ\t動詞,非自立,*,*,一段,連用形,づける,ヅケ,ズケ\n",
      "年\t名詞,一般,*,*,*,*,年,トシ,トシ\n",
      "・\t記号,一般,*,*,*,*,・,・,・\n",
      "2\t名詞,数,*,*,*,*,*\n",
      "年\t名詞,接尾,助数詞,*,*,*,年,ネン,ネン\n",
      "・\t記号,一般,*,*,*,*,・,・,・\n",
      "2\t名詞,数,*,*,*,*,*\n",
      "年月\t名詞,一般,*,*,*,*,年月,トシツキ,トシツキ\n",
      "学歴\t名詞,一般,*,*,*,*,学歴,ガクレキ,ガクレキ\n",
      "・\t記号,一般,*,*,*,*,・,・,・\n",
      "職歴\t名詞,一般,*,*,*,*,職歴,ショクレキ,ショクレキ\n",
      "年月\t名詞,一般,*,*,*,*,年月,トシツキ,トシツキ\n",
      "免許\t名詞,サ変接続,*,*,*,*,免許,メンキョ,メンキョ\n",
      "・\t記号,一般,*,*,*,*,・,・,・\n",
      "資格\t名詞,一般,*,*,*,*,資格,シカク,シカク\n",
      "201212\t名詞,数,*,*,*,*,*\n",
      "toeic\t名詞,一般,*,*,*,*,*\n",
      "公開\t名詞,サ変接続,*,*,*,*,公開,コウカイ,コーカイ\n",
      "テスト\t名詞,サ変接続,*,*,*,*,テスト,テスト,テスト\n",
      "800\t名詞,数,*,*,*,*,*\n",
      "点\t名詞,接尾,助数詞,*,*,*,点,テン,テン\n",
      "取得\t名詞,サ変接続,*,*,*,*,取得,シュトク,シュトク\n",
      "志望\t名詞,サ変接続,*,*,*,*,志望,シボウ,シボー\n",
      "動機\t名詞,一般,*,*,*,*,動機,ドウキ,ドーキ\n",
      "・\t記号,一般,*,*,*,*,・,・,・\n",
      "特技\t名詞,一般,*,*,*,*,特技,トクギ,トクギ\n",
      "・\t記号,一般,*,*,*,*,・,・,・\n",
      "アピール\t名詞,サ変接続,*,*,*,*,アピール,アピール,アピール\n",
      "ポイント\t名詞,一般,*,*,*,*,ポイント,ポイント,ポイント\n",
      "など\t助詞,副助詞,*,*,*,*,など,ナド,ナド\n",
      "donuts\t名詞,一般,*,*,*,*,*\n",
      "は\t助詞,係助詞,*,*,*,*,は,ハ,ワ\n",
      "、\t記号,読点,*,*,*,*,、,、,、\n",
      "サービス\t名詞,サ変接続,*,*,*,*,サービス,サービス,サービス\n",
      "や\t助詞,並立助詞,*,*,*,*,や,ヤ,ヤ\n",
      "ゲーム\t名詞,一般,*,*,*,*,ゲーム,ゲーム,ゲーム\n",
      "において\t助詞,格助詞,連語,*,*,*,において,ニオイテ,ニオイテ\n",
      "1\t名詞,数,*,*,*,*,*\n",
      "年\t名詞,接尾,助数詞,*,*,*,年,ネン,ネン\n",
      "、\t記号,読点,*,*,*,*,、,、,、\n",
      "2\t名詞,数,*,*,*,*,*\n",
      "年\t名詞,接尾,助数詞,*,*,*,年,ネン,ネン\n",
      "で\t助詞,格助詞,一般,*,*,*,で,デ,デ\n",
      "終わっ\t動詞,自立,*,*,五段・ラ行,連用タ接続,終わる,オワッ,オワッ\n",
      "て\t助詞,接続助詞,*,*,*,*,て,テ,テ\n",
      "しまう\t動詞,非自立,*,*,五段・ワ行促音便,基本形,しまう,シマウ,シマウ\n",
      "よう\t名詞,非自立,助動詞語幹,*,*,*,よう,ヨウ,ヨー\n",
      "な\t助動詞,*,*,*,特殊・ダ,体言接続,だ,ナ,ナ\n",
      "もの\t名詞,非自立,一般,*,*,*,もの,モノ,モノ\n",
      "で\t助動詞,*,*,*,特殊・ダ,連用形,だ,デ,デ\n",
      "は\t助詞,係助詞,*,*,*,*,は,ハ,ワ\n",
      "なく\t助動詞,*,*,*,特殊・ナイ,連用テ接続,ない,ナク,ナク\n",
      "、\t記号,読点,*,*,*,*,、,、,、\n",
      "世の中\t名詞,一般,*,*,*,*,世の中,ヨノナカ,ヨノナカ\n",
      "に\t助詞,格助詞,一般,*,*,*,に,ニ,ニ\n",
      "何らかの\t連体詞,*,*,*,*,*,何らかの,ナンラカノ,ナンラカノ\n",
      "価値\t名詞,一般,*,*,*,*,価値,カチ,カチ\n",
      "を\t助詞,格助詞,一般,*,*,*,を,ヲ,ヲ\n",
      "もたらし\t動詞,自立,*,*,五段・サ行,連用形,もたらす,モタラシ,モタラシ\n",
      "、\t記号,読点,*,*,*,*,、,、,、\n",
      "100\t名詞,数,*,*,*,*,*\n",
      "年\t名詞,接尾,助数詞,*,*,*,年,ネン,ネン\n",
      "先\t名詞,接尾,一般,*,*,*,先,サキ,サキ\n",
      "に\t助詞,格助詞,一般,*,*,*,に,ニ,ニ\n",
      "も\t助詞,係助詞,*,*,*,*,も,モ,モ\n",
      "その\t連体詞,*,*,*,*,*,その,ソノ,ソノ\n",
      "価値\t名詞,一般,*,*,*,*,価値,カチ,カチ\n",
      "が\t助詞,格助詞,一般,*,*,*,が,ガ,ガ\n",
      "残り\t動詞,自立,*,*,五段・ラ行,連用形,残る,ノコリ,ノコリ\n",
      "続ける\t動詞,非自立,*,*,一段,基本形,続ける,ツヅケル,ツズケル\n",
      "もの\t名詞,非自立,一般,*,*,*,もの,モノ,モノ\n",
      "を\t助詞,格助詞,一般,*,*,*,を,ヲ,ヲ\n",
      "目指し\t動詞,自立,*,*,五段・サ行,連用形,目指す,メザシ,メザシ\n",
      "て\t助詞,接続助詞,*,*,*,*,て,テ,テ\n",
      "プロダクト\t名詞,一般,*,*,*,*,プロダクト,プロダクト,プロダクト\n",
      "創り\t動詞,自立,*,*,五段・ラ行,連用形,創る,ツクリ,ツクリ\n",
      "を\t助詞,格助詞,一般,*,*,*,を,ヲ,ヲ\n",
      "し\t動詞,自立,*,*,サ変・スル,連用形,する,シ,シ\n",
      "て\t助詞,接続助詞,*,*,*,*,て,テ,テ\n",
      "い\t動詞,非自立,*,*,一段,連用形,いる,イ,イ\n",
      "ます\t助動詞,*,*,*,特殊・マス,基本形,ます,マス,マス\n",
      "。\t記号,句点,*,*,*,*,。,。,。\n",
      "その\t連体詞,*,*,*,*,*,その,ソノ,ソノ\n",
      "ため\t名詞,非自立,副詞可能,*,*,*,ため,タメ,タメ\n",
      "に\t助詞,格助詞,一般,*,*,*,に,ニ,ニ\n",
      "社会\t名詞,一般,*,*,*,*,社会,シャカイ,シャカイ\n",
      "や\t助詞,並立助詞,*,*,*,*,や,ヤ,ヤ\n",
      "時流\t名詞,一般,*,*,*,*,時流,ジリュウ,ジリュー\n",
      "に\t助詞,格助詞,一般,*,*,*,に,ニ,ニ\n",
      "変化\t名詞,サ変接続,*,*,*,*,変化,ヘンカ,ヘンカ\n",
      "を\t助詞,格助詞,一般,*,*,*,を,ヲ,ヲ\n",
      "もたらす\t動詞,自立,*,*,五段・サ行,基本形,もたらす,モタラス,モタラス\n",
      "もの\t名詞,非自立,一般,*,*,*,もの,モノ,モノ\n",
      "創り出し\t動詞,自立,*,*,五段・サ行,連用形,創り出す,ツクリダシ,ツクリダシ\n",
      "て\t助詞,接続助詞,*,*,*,*,て,テ,テ\n",
      "いこ\t動詞,非自立,*,*,五段・カ行促音便,未然ウ接続,いく,イコ,イコ\n",
      "う\t助動詞,*,*,*,不変化型,基本形,う,ウ,ウ\n",
      "という\t助詞,格助詞,連語,*,*,*,という,トイウ,トユウ\n",
      "想い\t名詞,一般,*,*,*,*,想い,オモイ,オモイ\n",
      "を\t助詞,格助詞,一般,*,*,*,を,ヲ,ヲ\n",
      "込め\t動詞,自立,*,*,一段,連用形,込める,コメ,コメ\n",
      "て\t助詞,接続助詞,*,*,*,*,て,テ,テ\n",
      "サービス\t名詞,サ変接続,*,*,*,*,サービス,サービス,サービス\n",
      "を\t助詞,格助詞,一般,*,*,*,を,ヲ,ヲ\n",
      "作り出し\t動詞,自立,*,*,五段・サ行,連用形,作り出す,ツクリダシ,ツクリダシ\n",
      "て\t助詞,接続助詞,*,*,*,*,て,テ,テ\n",
      "い\t動詞,非自立,*,*,一段,連用形,いる,イ,イ\n",
      "ます\t助動詞,*,*,*,特殊・マス,基本形,ます,マス,マス\n",
      "。\t記号,句点,*,*,*,*,。,。,。\n",
      "通勤\t名詞,サ変接続,*,*,*,*,通勤,ツウキン,ツーキン\n",
      "時間\t名詞,副詞可能,*,*,*,*,時間,ジカン,ジカン\n",
      "電車\t名詞,一般,*,*,*,*,電車,デンシャ,デンシャ\n",
      "約\t接頭詞,数接続,*,*,*,*,約,ヤク,ヤク\n",
      "1\t名詞,数,*,*,*,*,*\n",
      "時間\t名詞,接尾,助数詞,*,*,*,時間,ジカン,ジカン\n",
      "00\t名詞,数,*,*,*,*,*\n",
      "分\t名詞,接尾,助数詞,*,*,*,分,フン,フン\n",
      "扶養\t名詞,サ変接続,*,*,*,*,扶養,フヨウ,フヨー\n",
      "家族\t名詞,一般,*,*,*,*,家族,カゾク,カゾク\n",
      "数\t名詞,数,*,*,*,*,数,スウ,スー\n",
      "(\t名詞,サ変接続,*,*,*,*,*\n",
      "配偶\t名詞,一般,*,*,*,*,配偶,ハイグウ,ハイグー\n",
      "者\t名詞,接尾,一般,*,*,*,者,シャ,シャ\n",
      "を\t助詞,格助詞,一般,*,*,*,を,ヲ,ヲ\n",
      "除く\t動詞,自立,*,*,五段・カ行イ音便,基本形,除く,ノゾク,ノゾク\n",
      ")\t名詞,サ変接続,*,*,*,*,*\n",
      "0\t名詞,数,*,*,*,*,*\n",
      "人\t名詞,接尾,助数詞,*,*,*,人,ニン,ニン\n",
      "配偶\t名詞,一般,*,*,*,*,配偶,ハイグウ,ハイグー\n",
      "者\t名詞,接尾,一般,*,*,*,者,シャ,シャ\n",
      "有\t名詞,固有名詞,人名,名,*,*,有,ユウ,ユー\n",
      "・\t記号,一般,*,*,*,*,・,・,・\n",
      "無\t接頭詞,名詞接続,*,*,*,*,無,ム,ム\n",
      "配偶\t名詞,一般,*,*,*,*,配偶,ハイグウ,ハイグー\n",
      "者\t名詞,接尾,一般,*,*,*,者,シャ,シャ\n",
      "の\t助詞,連体化,*,*,*,*,の,ノ,ノ\n",
      "扶養\t名詞,サ変接続,*,*,*,*,扶養,フヨウ,フヨー\n",
      "義務\t名詞,一般,*,*,*,*,義務,ギム,ギム\n",
      "有\t名詞,固有名詞,人名,名,*,*,有,ユウ,ユー\n",
      "・\t記号,一般,*,*,*,*,・,・,・\n",
      "無\t接頭詞,名詞接続,*,*,*,*,無,ム,ム\n",
      "本人\t名詞,一般,*,*,*,*,本人,ホンニン,ホンニン\n",
      "希望\t名詞,サ変接続,*,*,*,*,希望,キボウ,キボー\n",
      "欄\t名詞,一般,*,*,*,*,欄,ラン,ラン\n",
      "(\t名詞,サ変接続,*,*,*,*,*\n",
      "特に\t副詞,一般,*,*,*,*,特に,トクニ,トクニ\n",
      "給料\t名詞,一般,*,*,*,*,給料,キュウリョウ,キューリョー\n",
      "・\t記号,一般,*,*,*,*,・,・,・\n",
      "職種\t名詞,一般,*,*,*,*,職種,ショクシュ,ショクシュ\n",
      "・\t記号,一般,*,*,*,*,・,・,・\n",
      "勤務\t名詞,サ変接続,*,*,*,*,勤務,キンム,キンム\n",
      "時間\t名詞,副詞可能,*,*,*,*,時間,ジカン,ジカン\n",
      "・\t記号,一般,*,*,*,*,・,・,・\n",
      "勤務\t名詞,サ変接続,*,*,*,*,勤務,キンム,キンム\n",
      "地\t名詞,接尾,一般,*,*,*,地,チ,チ\n",
      "・\t記号,一般,*,*,*,*,・,・,・\n",
      "その他\t名詞,代名詞,一般,*,*,*,その他,ソノタ,ソノタ\n",
      "について\t助詞,格助詞,連語,*,*,*,について,ニツイテ,ニツイテ\n",
      "希望\t名詞,サ変接続,*,*,*,*,希望,キボウ,キボー\n",
      "が\t助詞,格助詞,一般,*,*,*,が,ガ,ガ\n",
      "あれ\t動詞,自立,*,*,五段・ラ行,仮定形,ある,アレ,アレ\n",
      "ば\t助詞,接続助詞,*,*,*,*,ば,バ,バ\n",
      "記入\t名詞,サ変接続,*,*,*,*,記入,キニュウ,キニュー\n",
      ")\t名詞,サ変接続,*,*,*,*,*\n",
      "donuts\t名詞,一般,*,*,*,*,*\n",
      "は\t助詞,係助詞,*,*,*,*,は,ハ,ワ\n",
      "、\t記号,読点,*,*,*,*,、,、,、\n",
      "サービス\t名詞,サ変接続,*,*,*,*,サービス,サービス,サービス\n",
      "や\t助詞,並立助詞,*,*,*,*,や,ヤ,ヤ\n",
      "ゲーム\t名詞,一般,*,*,*,*,ゲーム,ゲーム,ゲーム\n",
      "において\t助詞,格助詞,連語,*,*,*,において,ニオイテ,ニオイテ\n",
      "1\t名詞,数,*,*,*,*,*\n",
      "年\t名詞,接尾,助数詞,*,*,*,年,ネン,ネン\n",
      "、\t記号,読点,*,*,*,*,、,、,、\n",
      "2\t名詞,数,*,*,*,*,*\n",
      "年\t名詞,接尾,助数詞,*,*,*,年,ネン,ネン\n",
      "で\t助詞,格助詞,一般,*,*,*,で,デ,デ\n",
      "終わっ\t動詞,自立,*,*,五段・ラ行,連用タ接続,終わる,オワッ,オワッ\n",
      "て\t助詞,接続助詞,*,*,*,*,て,テ,テ\n",
      "しまう\t動詞,非自立,*,*,五段・ワ行促音便,基本形,しまう,シマウ,シマウ\n",
      "よう\t名詞,非自立,助動詞語幹,*,*,*,よう,ヨウ,ヨー\n",
      "な\t助動詞,*,*,*,特殊・ダ,体言接続,だ,ナ,ナ\n",
      "もの\t名詞,非自立,一般,*,*,*,もの,モノ,モノ\n",
      "で\t助動詞,*,*,*,特殊・ダ,連用形,だ,デ,デ\n",
      "は\t助詞,係助詞,*,*,*,*,は,ハ,ワ\n",
      "なく\t助動詞,*,*,*,特殊・ナイ,連用テ接続,ない,ナク,ナク\n",
      "、\t記号,読点,*,*,*,*,、,、,、\n",
      "世の中\t名詞,一般,*,*,*,*,世の中,ヨノナカ,ヨノナカ\n",
      "に\t助詞,格助詞,一般,*,*,*,に,ニ,ニ\n",
      "何らかの\t連体詞,*,*,*,*,*,何らかの,ナンラカノ,ナンラカノ\n",
      "価値\t名詞,一般,*,*,*,*,価値,カチ,カチ\n",
      "を\t助詞,格助詞,一般,*,*,*,を,ヲ,ヲ\n",
      "もたらし\t動詞,自立,*,*,五段・サ行,連用形,もたらす,モタラシ,モタラシ\n",
      "、\t記号,読点,*,*,*,*,、,、,、\n",
      "100\t名詞,数,*,*,*,*,*\n",
      "年\t名詞,接尾,助数詞,*,*,*,年,ネン,ネン\n",
      "先\t名詞,接尾,一般,*,*,*,先,サキ,サキ\n",
      "に\t助詞,格助詞,一般,*,*,*,に,ニ,ニ\n",
      "も\t助詞,係助詞,*,*,*,*,も,モ,モ\n",
      "その\t連体詞,*,*,*,*,*,その,ソノ,ソノ\n",
      "価値\t名詞,一般,*,*,*,*,価値,カチ,カチ\n",
      "が\t助詞,格助詞,一般,*,*,*,が,ガ,ガ\n",
      "残り\t動詞,自立,*,*,五段・ラ行,連用形,残る,ノコリ,ノコリ\n",
      "続ける\t動詞,非自立,*,*,一段,基本形,続ける,ツヅケル,ツズケル\n",
      "もの\t名詞,非自立,一般,*,*,*,もの,モノ,モノ\n",
      "を\t助詞,格助詞,一般,*,*,*,を,ヲ,ヲ\n",
      "目指し\t動詞,自立,*,*,五段・サ行,連用形,目指す,メザシ,メザシ\n",
      "て\t助詞,接続助詞,*,*,*,*,て,テ,テ\n",
      "プロダクト\t名詞,一般,*,*,*,*,プロダクト,プロダクト,プロダクト\n",
      "創り\t動詞,自立,*,*,五段・ラ行,連用形,創る,ツクリ,ツクリ\n",
      "を\t助詞,格助詞,一般,*,*,*,を,ヲ,ヲ\n",
      "し\t動詞,自立,*,*,サ変・スル,連用形,する,シ,シ\n",
      "て\t助詞,接続助詞,*,*,*,*,て,テ,テ\n",
      "い\t動詞,非自立,*,*,一段,連用形,いる,イ,イ\n",
      "ます\t助動詞,*,*,*,特殊・マス,基本形,ます,マス,マス\n",
      "。\t記号,句点,*,*,*,*,。,。,。\n",
      "その\t連体詞,*,*,*,*,*,その,ソノ,ソノ\n",
      "ため\t名詞,非自立,副詞可能,*,*,*,ため,タメ,タメ\n",
      "に\t助詞,格助詞,一般,*,*,*,に,ニ,ニ\n",
      "社会\t名詞,一般,*,*,*,*,社会,シャカイ,シャカイ\n",
      "や\t助詞,並立助詞,*,*,*,*,や,ヤ,ヤ\n",
      "時流\t名詞,一般,*,*,*,*,時流,ジリュウ,ジリュー\n",
      "に\t助詞,格助詞,一般,*,*,*,に,ニ,ニ\n",
      "変化\t名詞,サ変接続,*,*,*,*,変化,ヘンカ,ヘンカ\n",
      "を\t助詞,格助詞,一般,*,*,*,を,ヲ,ヲ\n",
      "もたらす\t動詞,自立,*,*,五段・サ行,基本形,もたらす,モタラス,モタラス\n",
      "もの\t名詞,非自立,一般,*,*,*,もの,モノ,モノ\n",
      "創り出し\t動詞,自立,*,*,五段・サ行,連用形,創り出す,ツクリダシ,ツクリダシ\n",
      "て\t助詞,接続助詞,*,*,*,*,て,テ,テ\n",
      "いこ\t動詞,非自立,*,*,五段・カ行促音便,未然ウ接続,いく,イコ,イコ\n",
      "う\t助動詞,*,*,*,不変化型,基本形,う,ウ,ウ\n",
      "という\t助詞,格助詞,連語,*,*,*,という,トイウ,トユウ\n",
      "想い\t名詞,一般,*,*,*,*,想い,オモイ,オモイ\n",
      "を\t助詞,格助詞,一般,*,*,*,を,ヲ,ヲ\n",
      "込め\t動詞,自立,*,*,一段,連用形,込める,コメ,コメ\n",
      "て\t助詞,接続助詞,*,*,*,*,て,テ,テ\n",
      "サービス\t名詞,サ変接続,*,*,*,*,サービス,サービス,サービス\n",
      "を\t助詞,格助詞,一般,*,*,*,を,ヲ,ヲ\n",
      "作り出し\t動詞,自立,*,*,五段・サ行,連用形,作り出す,ツクリダシ,ツクリダシ\n",
      "て\t助詞,接続助詞,*,*,*,*,て,テ,テ\n",
      "い\t動詞,非自立,*,*,一段,連用形,いる,イ,イ\n",
      "ます\t助動詞,*,*,*,特殊・マス,基本形,ます,マス,マス\n",
      "。\t記号,句点,*,*,*,*,。,。,。\n",
      "EOS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import MeCab\n",
    "tagger = MeCab.Tagger()\n",
    "print(tagger.parse(mytext))\n",
    "t = tagger.parse(mytext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two-t\n",
      "two-o\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s = 'one-two-three-two-one'\n",
    "\n",
    "pull_out(s,'two', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "りがなさとういちろう名前青柳文蔵1995\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mytext = '履歴書2019年12月25日現在ふりがなさとういちろう名前青柳文蔵1995年1月1日生(満24歳)男・女ふりがなとうきょうとちよだくさざんたわー電話000-0000-0000emailtest1@sample.comふりがな電話email年月学歴・職歴学歴20104東京都砂糖高等学校入学20133東京都砂糖高等学校卒業20134東京都菓子大学入学20173東京都菓子大学卒業職歴201710donuts株式会社入社現在に至る以上現住所〒100-0000東京都千代田区サザンタワー現住所〒(現住所以外に連絡を希望する場合のみ入力)証明写真縦36mm40mm横24mm30mm本人単身胸から上裏面のりづけ年・2年・2年月学歴・職歴年月免許・資格201212toeic公開テスト800点取得志望動機・特技・アピールポイントなどdonutsは、サービスやゲームにおいて1年、2年で終わってしまうようなものではなく、世の中に何らかの価値をもたらし、100年先にもその価値が残り続けるものを目指してプロダクト創りをしています。そのために社会や時流に変化をもたらすもの創り出していこうという想いを込めてサービスを作り出しています。通勤時間電車約1時間00分扶養家族数(配偶者を除く)0人配偶者有・無配偶者の扶養義務有・無本人希望欄(特に給料・職種・勤務時間・勤務地・その他について希望があれば記入)donutsは、サービスやゲームにおいて1年、2年で終わってしまうようなものではなく、世の中に何らかの価値をもたらし、100年先にもその価値が残り続けるものを目指してプロダクト創りをしています。そのために社会や時流に変化をもたらすもの創り出していこうという想いを込めてサービスを作り出しています。'\n",
    "\n",
    "pull_out(mytext, '名前', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",自立,*,*,形容詞・アウオ段,連用ゴザイ接続,さとい,サトウ,サトー\n",
      "いちろう\t名詞,固有名詞,人名,名,*,*,いちろう,イチロウ,イチロー\n",
      "名前\t名詞,一般,*,*,*,*,名前,ナマエ,ナマ\n",
      "*,配偶,ハイグウ,ハイグー\n",
      "者\t名詞,接尾,一般,*,*,*,者,シャ,シャ\n",
      "有\t名詞,固有名詞,人名,名,*,*,有,ユウ,ユー\n",
      "・\t記号,一般,*,*,*,*,・,・,・\n",
      "無\t接頭詞,名詞接続,\n",
      ",*,扶養,フヨウ,フヨー\n",
      "義務\t名詞,一般,*,*,*,*,義務,ギム,ギム\n",
      "有\t名詞,固有名詞,人名,名,*,*,有,ユウ,ユー\n",
      "・\t記号,一般,*,*,*,*,・,・,・\n",
      "無\t接頭詞,名詞接続,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pull_out(t, '人名', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "履歴書2019年12月25日現在ふりがなさとういちろ\n",
      "False\n",
      "履歴書2019年12月25日現在ふりがなさとういちろ\n",
      "False\n",
      "履歴書2019年12月25日現在ふりがなさとういちろ\n",
      "False\n",
      "履歴書2019年12月25日現在ふりがなさとういちろ\n",
      "False\n",
      "履歴書2019年12月25日現在ふりがなさとういちろ\n",
      "False\n",
      "履歴書2019年12月25日現在ふりがなさとういちろ\n",
      "False\n",
      "履歴書2019年12月25日現在ふりがなさとういちろ\n",
      "False\n",
      "履歴書2019年12月25日現在ふりがなさとういちろ\n",
      "False\n",
      "履歴書2019年12月25日現在ふりがなさとういちろ\n",
      "False\n",
      "履歴書2019年12月25日現在ふりがなさとういちろ\n",
      "False\n",
      "履歴書2019年12月25日現在ふりがなさとういちろ\n",
      "False\n",
      "履歴書2019年12月25日現在ふりがなさとういちろ\n",
      "False\n",
      "履歴書2019年12月25日現在ふりがなさとういちろ\n",
      "False\n",
      "履歴書2019年12月25日現在ふりがなさとういちろ\n",
      "False\n",
      "履歴書2019年12月25日現在ふりがなさとういちろ\n",
      "False\n",
      "履歴書2019年12月25日現在ふりがなさとういちろ\n",
      "False\n",
      "履歴書2019年12月25日現在ふりがなさとういちろ\n",
      "False\n",
      "履歴書2019年12月25日現在ふりがなさとういちろ\n",
      "False\n",
      "履歴書2019年12月25日現在ふりがなさとういちろ\n",
      "False\n",
      "履歴書2019年12月25日現在ふりがなさとういちろ\n",
      "False\n",
      "履歴書2019年12月25日現在ふりがなさとういちろ\n",
      "False\n",
      "履歴書2019年12月25日現在ふりがなさとういちろ\n",
      "False\n",
      "履歴書2019年12月25日現在ふりがなさとういちろ\n",
      "False\n",
      "履歴書2019年12月25日現在ふりがなさとういちろ\n",
      "False\n",
      "履歴書2019年12月25日現在ふりがなさとういちろ\n",
      "False\n",
      "履歴書2019年12月25日現在ふりがなさとういちろ\n",
      "False\n",
      "履歴書2019年12月25日現在ふりがなさとういちろ\n",
      "False\n",
      "履歴書2019年12月25日現在ふりがなさとういちろ\n",
      "False\n",
      "履歴書2019年12月25日現在ふりがなさとういちろ\n",
      "False\n",
      "履歴書2019年12月25日現在ふりがなさとういちろ\n",
      "False\n",
      "履歴書2019年12月25日現在ふりがなさとういちろ\n",
      "False\n",
      "履歴書2019年12月25日現在ふりがなさとういちろ\n",
      "False\n",
      "履歴書2019年12月25日現在ふりがなさとういちろ\n",
      "False\n",
      "履歴書2019年12月25日現在ふりがなさとういちろ\n",
      "False\n",
      "履歴書2019年12月25日現在ふりがなさとういちろ\n",
      "False\n",
      "履歴書2019年12月25日現在ふりがなさとういちろ\n",
      "False\n",
      "履歴書2019年12月25日現在ふりがなさとういちろ\n",
      "False\n",
      "履歴書2019年12月25日現在ふりがなさとういちろ\n",
      "False\n",
      "履歴書2019年12月25日現在ふりがなさとういちろ\n",
      "False\n",
      "履歴書2019年12月25日現在ふりがなさとういちろ\n",
      "False\n",
      "履歴書2019年12月25日現在ふりがなさとういちろ\n",
      "False\n",
      "履歴書2019年12月25日現在ふりがなさとういちろ\n",
      "False\n",
      "履歴書2019年12月25日現在ふりがなさとういちろ\n",
      "False\n",
      "履歴書2019年12月25日現在ふりがなさとういちろ\n",
      "False\n",
      "履歴書2019年12月25日現在ふりがなさとういちろ\n",
      "False\n",
      "履歴書2019年12月25日現在ふりがなさとういちろ\n",
      "False\n",
      "履歴書2019年12月25日現在ふりがなさとういちろ\n",
      "False\n",
      "履歴書2019年12月25日現在ふりがなさとういちろ\n",
      "False\n",
      "履歴書2019年12月25日現在ふりがなさとういちろ\n",
      "False\n",
      "履歴書2019年12月25日現在ふりがなさとういちろ\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "t = '履歴書2019年12月25日現在ふりがなさとういちろ'\n",
    "def pull_out(text, word):\n",
    "    num = 0\n",
    "    for i in range(50):\n",
    "        evalu = 'two' in text[num:]\n",
    "        print(text[num:])\n",
    "        print(evalu)\n",
    "        if  evalu == True:\n",
    "            num = text.find(word, num+1)\n",
    "            print(s[num:num+5])\n",
    "\n",
    "pull_out(t, '年')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "履歴書2019年12月25日現在ふりがなさとういちろ\n",
      "True\n",
      "o-thr\n",
      "6\n",
      "9年12月25日現在ふりがなさとういちろ\n",
      "True\n",
      "\n",
      "-1\n",
      "ろ\n",
      "False\n",
      "-1\n",
      "ろ\n",
      "False\n",
      "-1\n",
      "ろ\n",
      "False\n",
      "-1\n",
      "ろ\n",
      "False\n",
      "-1\n",
      "ろ\n",
      "False\n",
      "-1\n",
      "ろ\n",
      "False\n",
      "-1\n",
      "ろ\n",
      "False\n",
      "-1\n",
      "ろ\n",
      "False\n",
      "-1\n",
      "ろ\n",
      "False\n",
      "-1\n",
      "ろ\n",
      "False\n",
      "-1\n",
      "ろ\n",
      "False\n",
      "-1\n",
      "ろ\n",
      "False\n",
      "-1\n",
      "ろ\n",
      "False\n",
      "-1\n",
      "ろ\n",
      "False\n",
      "-1\n",
      "ろ\n",
      "False\n",
      "-1\n",
      "ろ\n",
      "False\n",
      "-1\n",
      "ろ\n",
      "False\n",
      "-1\n",
      "ろ\n",
      "False\n",
      "-1\n",
      "ろ\n",
      "False\n",
      "-1\n",
      "ろ\n",
      "False\n",
      "-1\n",
      "ろ\n",
      "False\n",
      "-1\n",
      "ろ\n",
      "False\n",
      "-1\n",
      "ろ\n",
      "False\n",
      "-1\n",
      "ろ\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "t = '履歴書2019年12月25日現在ふりがなさとういちろ'\n",
    "\n",
    "word = '9'\n",
    "def pull_out(text, word):\n",
    "    num = 0\n",
    "    for i in range(len(t)):\n",
    "        print(num)       \n",
    "        evalu = word in text[num:]\n",
    "        print(text[num:])\n",
    "        print(evalu)\n",
    "        if  evalu == True:\n",
    "            num = text.find(word, num+1)\n",
    "            print(s[num:num+5])\n",
    "            \n",
    "pull_out(t, word)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 名字検索AI作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaabbbccc -> aaaBBBccc\n"
     ]
    }
   ],
   "source": [
    "#対象の文字列\n",
    "src = \"aaabbbccc\"\n",
    " \n",
    "# すべて置換\n",
    "dst = src.replace(\"b\", \"B\")\n",
    " \n",
    "print(src, \"->\", dst)    # aaabbbccc -> aaaBBBccc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "こんにちは。\r\n",
      "ありがとう！\n",
      "こんにちは。ありがとう！\n"
     ]
    }
   ],
   "source": [
    "text = 'こんにちは。\\r\\nありがとう！'\n",
    "print(text)\n",
    "\n",
    "\n",
    "text = text.replace('\\r\\n','')\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='./name1' mode='r' encoding='UTF-8'>\n",
      "佐藤\n",
      "\n",
      "佐藤\n"
     ]
    }
   ],
   "source": [
    "with open('./name1') as f:\n",
    "    read_data = list(f)\n",
    "    print(f)\n",
    "    \n",
    "print(read_data[0])\n",
    "print(read_data[0].replace('\\n', ''))\n",
    "    \n",
    "    \n",
    "name_list = [r.replace(\"\\n\", \"\") for r in read_data ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram(words, n):\n",
    "    return list(zip(*(words[i:] for i in range(n))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['名前佐藤199', '名前鈴木199', '名前高橋199', '名前田中199', '名前伊藤199', '名前山本199', '名前渡辺199', '名前中村199', '名前小林199', '名前加藤199', '名前吉田199', '名前山田199', '名前木199', '名前山口199', '名前松本199', '名前井上199', '名前木村199', '名前林199', '名前斎藤199', '名前清水199', '名前山崎199', '名前阿部199', '名前森199', '名前池田199', '名前橋本199', '名前山下199', '名前石川199', '名前中島199', '名前前田199', '名前藤田199', '名前後藤199', '名前小川199', '名前岡田199', '名前村上199', '名前長谷川199', '名前近藤199', '名前石井199', '名前斉藤199', '名前坂本199', '名前遠藤199', '名前藤井199', '名前青木199', '名前福田199', '名前三浦199', '名前西村199', '名前藤原199', '名前太田199', '名前松田199', '名前原田199', '名前岡本199', '名前中野199', '名前中川199', '名前小野199', '名前田村199', '名前竹内199', '名前金子199', '名前中山199', '名前和田199', '名前石田199', '名前工藤199', '名前上田199', '名前原199', '名前森田199', '名前酒井199', '名前横山199', '名前柴田199', '名前宮崎199', '名前宮本199', '名前内田199', '名前高木199', '名前谷口199', '名前安藤199', '名前丸山199', '名前今井199', '名前大野199', '名前高田199', '名前菅原199', '名前河野199', '名前武田199', '名前藤本199', '名前上野199', '名前杉山199', '名前千葉199', '名前村田199', '名前増田199', '名前小島199', '名前小山199', '名前大塚199', '名前平野199', '名前久保199', '名前渡部199', '名前松井199', '名前菊地199', '名前岩崎199', '名前松尾199', '名前佐野199', '名前木下199', '名前野口199', '名前野村199', '名前新199', '名前199', '名前199', '名前199']\n"
     ]
    }
   ],
   "source": [
    "t_p = []\n",
    "\n",
    "for ii in range(len(name_list)):\n",
    "    noize_text = '名前' + name_list[ii] + '199'\n",
    "    t_p.append(noize_text)\n",
    "\n",
    "print(t_p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label,text\r",
      "\r\n",
      "0,名前佐\r",
      "\r\n",
      "0,前佐藤\r",
      "\r\n",
      "0,佐藤1\r",
      "\r\n",
      "0,藤19\r",
      "\r\n",
      "0,199\r",
      "\r\n",
      "1,名前鈴\r",
      "\r\n",
      "1,前鈴木\r",
      "\r\n",
      "1,鈴木1\r",
      "\r\n",
      "1,木19\r",
      "\r\n",
      "1,199\r",
      "\r\n",
      "2,名前高\r",
      "\r\n",
      "2,前高橋\r",
      "\r\n",
      "2,高橋1\r",
      "\r\n",
      "2,橋19\r",
      "\r\n",
      "2,199\r",
      "\r\n",
      "3,名前田\r",
      "\r\n",
      "3,前田中\r",
      "\r\n",
      "3,田中1\r",
      "\r\n",
      "3,中19\r",
      "\r\n",
      "3,199\r",
      "\r\n",
      "4,名前伊\r",
      "\r\n",
      "4,前伊藤\r",
      "\r\n",
      "4,伊藤1\r",
      "\r\n",
      "4,藤19\r",
      "\r\n",
      "4,199\r",
      "\r\n",
      "5,名前山\r",
      "\r\n",
      "5,前山本\r",
      "\r\n",
      "5,山本1\r",
      "\r\n",
      "5,本19\r",
      "\r\n",
      "5,199\r",
      "\r\n",
      "6,名前渡\r",
      "\r\n",
      "6,前渡辺\r",
      "\r\n",
      "6,渡辺1\r",
      "\r\n",
      "6,辺19\r",
      "\r\n",
      "6,199\r",
      "\r\n",
      "7,名前中\r",
      "\r\n",
      "7,前中村\r",
      "\r\n",
      "7,中村1\r",
      "\r\n",
      "7,村19\r",
      "\r\n",
      "7,199\r",
      "\r\n",
      "8,名前小\r",
      "\r\n",
      "8,前小林\r",
      "\r\n",
      "8,小林1\r",
      "\r\n",
      "8,林19\r",
      "\r\n",
      "8,199\r",
      "\r\n",
      "9,名前加\r",
      "\r\n",
      "9,前加藤\r",
      "\r\n",
      "9,加藤1\r",
      "\r\n",
      "9,藤19\r",
      "\r\n",
      "9,199\r",
      "\r\n",
      "10,名前吉\r",
      "\r\n",
      "10,前吉田\r",
      "\r\n",
      "10,吉田1\r",
      "\r\n",
      "10,田19\r",
      "\r\n",
      "10,199\r",
      "\r\n",
      "11,名前山\r",
      "\r\n",
      "11,前山田\r",
      "\r\n",
      "11,山田1\r",
      "\r\n",
      "11,田19\r",
      "\r\n",
      "11,199\r",
      "\r\n",
      "12,名前木\r",
      "\r\n",
      "12,前木1\r",
      "\r\n",
      "12,木19\r",
      "\r\n",
      "12,199\r",
      "\r\n",
      "13,名前山\r",
      "\r\n",
      "13,前山口\r",
      "\r\n",
      "13,山口1\r",
      "\r\n",
      "13,口19\r",
      "\r\n",
      "13,199\r",
      "\r\n",
      "14,名前松\r",
      "\r\n",
      "14,前松本\r",
      "\r\n",
      "14,松本1\r",
      "\r\n",
      "14,本19\r",
      "\r\n",
      "14,199\r",
      "\r\n",
      "15,名前井\r",
      "\r\n",
      "15,前井上\r",
      "\r\n",
      "15,井上1\r",
      "\r\n",
      "15,上19\r",
      "\r\n",
      "15,199\r",
      "\r\n",
      "16,名前木\r",
      "\r\n",
      "16,前木村\r",
      "\r\n",
      "16,木村1\r",
      "\r\n",
      "16,村19\r",
      "\r\n",
      "16,199\r",
      "\r\n",
      "17,名前林\r",
      "\r\n",
      "17,前林1\r",
      "\r\n",
      "17,林19\r",
      "\r\n",
      "17,199\r",
      "\r\n",
      "18,名前斎\r",
      "\r\n",
      "18,前斎藤\r",
      "\r\n",
      "18,斎藤1\r",
      "\r\n",
      "18,藤19\r",
      "\r\n",
      "18,199\r",
      "\r\n",
      "19,名前清\r",
      "\r\n",
      "19,前清水\r",
      "\r\n",
      "19,清水1\r",
      "\r\n",
      "19,水19\r",
      "\r\n",
      "19,199\r",
      "\r\n",
      "20,名前山\r",
      "\r\n",
      "20,前山崎\r",
      "\r\n",
      "20,山崎1\r",
      "\r\n",
      "20,崎19\r",
      "\r\n",
      "20,199\r",
      "\r\n",
      "21,名前阿\r",
      "\r\n",
      "21,前阿部\r",
      "\r\n",
      "21,阿部1\r",
      "\r\n",
      "21,部19\r",
      "\r\n",
      "21,199\r",
      "\r\n",
      "22,名前森\r",
      "\r\n",
      "22,前森1\r",
      "\r\n",
      "22,森19\r",
      "\r\n",
      "22,199\r",
      "\r\n",
      "23,名前池\r",
      "\r\n",
      "23,前池田\r",
      "\r\n",
      "23,池田1\r",
      "\r\n",
      "23,田19\r",
      "\r\n",
      "23,199\r",
      "\r\n",
      "24,名前橋\r",
      "\r\n",
      "24,前橋本\r",
      "\r\n",
      "24,橋本1\r",
      "\r\n",
      "24,本19\r",
      "\r\n",
      "24,199\r",
      "\r\n",
      "25,名前山\r",
      "\r\n",
      "25,前山下\r",
      "\r\n",
      "25,山下1\r",
      "\r\n",
      "25,下19\r",
      "\r\n",
      "25,199\r",
      "\r\n",
      "26,名前石\r",
      "\r\n",
      "26,前石川\r",
      "\r\n",
      "26,石川1\r",
      "\r\n",
      "26,川19\r",
      "\r\n",
      "26,199\r",
      "\r\n",
      "27,名前中\r",
      "\r\n",
      "27,前中島\r",
      "\r\n",
      "27,中島1\r",
      "\r\n",
      "27,島19\r",
      "\r\n",
      "27,199\r",
      "\r\n",
      "28,名前前\r",
      "\r\n",
      "28,前前田\r",
      "\r\n",
      "28,前田1\r",
      "\r\n",
      "28,田19\r",
      "\r\n",
      "28,199\r",
      "\r\n",
      "29,名前藤\r",
      "\r\n",
      "29,前藤田\r",
      "\r\n",
      "29,藤田1\r",
      "\r\n",
      "29,田19\r",
      "\r\n",
      "29,199\r",
      "\r\n",
      "30,名前後\r",
      "\r\n",
      "30,前後藤\r",
      "\r\n",
      "30,後藤1\r",
      "\r\n",
      "30,藤19\r",
      "\r\n",
      "30,199\r",
      "\r\n",
      "31,名前小\r",
      "\r\n",
      "31,前小川\r",
      "\r\n",
      "31,小川1\r",
      "\r\n",
      "31,川19\r",
      "\r\n",
      "31,199\r",
      "\r\n",
      "32,名前岡\r",
      "\r\n",
      "32,前岡田\r",
      "\r\n",
      "32,岡田1\r",
      "\r\n",
      "32,田19\r",
      "\r\n",
      "32,199\r",
      "\r\n",
      "33,名前村\r",
      "\r\n",
      "33,前村上\r",
      "\r\n",
      "33,村上1\r",
      "\r\n",
      "33,上19\r",
      "\r\n",
      "33,199\r",
      "\r\n",
      "34,名前長\r",
      "\r\n",
      "34,前長谷\r",
      "\r\n",
      "34,長谷川\r",
      "\r\n",
      "34,谷川1\r",
      "\r\n",
      "34,川19\r",
      "\r\n",
      "34,199\r",
      "\r\n",
      "35,名前近\r",
      "\r\n",
      "35,前近藤\r",
      "\r\n",
      "35,近藤1\r",
      "\r\n",
      "35,藤19\r",
      "\r\n",
      "35,199\r",
      "\r\n",
      "36,名前石\r",
      "\r\n",
      "36,前石井\r",
      "\r\n",
      "36,石井1\r",
      "\r\n",
      "36,井19\r",
      "\r\n",
      "36,199\r",
      "\r\n",
      "37,名前斉\r",
      "\r\n",
      "37,前斉藤\r",
      "\r\n",
      "37,斉藤1\r",
      "\r\n",
      "37,藤19\r",
      "\r\n",
      "37,199\r",
      "\r\n",
      "38,名前坂\r",
      "\r\n",
      "38,前坂本\r",
      "\r\n",
      "38,坂本1\r",
      "\r\n",
      "38,本19\r",
      "\r\n",
      "38,199\r",
      "\r\n",
      "39,名前遠\r",
      "\r\n",
      "39,前遠藤\r",
      "\r\n",
      "39,遠藤1\r",
      "\r\n",
      "39,藤19\r",
      "\r\n",
      "39,199\r",
      "\r\n",
      "40,名前藤\r",
      "\r\n",
      "40,前藤井\r",
      "\r\n",
      "40,藤井1\r",
      "\r\n",
      "40,井19\r",
      "\r\n",
      "40,199\r",
      "\r\n",
      "41,名前青\r",
      "\r\n",
      "41,前青木\r",
      "\r\n",
      "41,青木1\r",
      "\r\n",
      "41,木19\r",
      "\r\n",
      "41,199\r",
      "\r\n",
      "42,名前福\r",
      "\r\n",
      "42,前福田\r",
      "\r\n",
      "42,福田1\r",
      "\r\n",
      "42,田19\r",
      "\r\n",
      "42,199\r",
      "\r\n",
      "43,名前三\r",
      "\r\n",
      "43,前三浦\r",
      "\r\n",
      "43,三浦1\r",
      "\r\n",
      "43,浦19\r",
      "\r\n",
      "43,199\r",
      "\r\n",
      "44,名前西\r",
      "\r\n",
      "44,前西村\r",
      "\r\n",
      "44,西村1\r",
      "\r\n",
      "44,村19\r",
      "\r\n",
      "44,199\r",
      "\r\n",
      "45,名前藤\r",
      "\r\n",
      "45,前藤原\r",
      "\r\n",
      "45,藤原1\r",
      "\r\n",
      "45,原19\r",
      "\r\n",
      "45,199\r",
      "\r\n",
      "46,名前太\r",
      "\r\n",
      "46,前太田\r",
      "\r\n",
      "46,太田1\r",
      "\r\n",
      "46,田19\r",
      "\r\n",
      "46,199\r",
      "\r\n",
      "47,名前松\r",
      "\r\n",
      "47,前松田\r",
      "\r\n",
      "47,松田1\r",
      "\r\n",
      "47,田19\r",
      "\r\n",
      "47,199\r",
      "\r\n",
      "48,名前原\r",
      "\r\n",
      "48,前原田\r",
      "\r\n",
      "48,原田1\r",
      "\r\n",
      "48,田19\r",
      "\r\n",
      "48,199\r",
      "\r\n",
      "49,名前岡\r",
      "\r\n",
      "49,前岡本\r",
      "\r\n",
      "49,岡本1\r",
      "\r\n",
      "49,本19\r",
      "\r\n",
      "49,199\r",
      "\r\n",
      "50,名前中\r",
      "\r\n",
      "50,前中野\r",
      "\r\n",
      "50,中野1\r",
      "\r\n",
      "50,野19\r",
      "\r\n",
      "50,199\r",
      "\r\n",
      "51,名前中\r",
      "\r\n",
      "51,前中川\r",
      "\r\n",
      "51,中川1\r",
      "\r\n",
      "51,川19\r",
      "\r\n",
      "51,199\r",
      "\r\n",
      "52,名前小\r",
      "\r\n",
      "52,前小野\r",
      "\r\n",
      "52,小野1\r",
      "\r\n",
      "52,野19\r",
      "\r\n",
      "52,199\r",
      "\r\n",
      "53,名前田\r",
      "\r\n",
      "53,前田村\r",
      "\r\n",
      "53,田村1\r",
      "\r\n",
      "53,村19\r",
      "\r\n",
      "53,199\r",
      "\r\n",
      "54,名前竹\r",
      "\r\n",
      "54,前竹内\r",
      "\r\n",
      "54,竹内1\r",
      "\r\n",
      "54,内19\r",
      "\r\n",
      "54,199\r",
      "\r\n",
      "55,名前金\r",
      "\r\n",
      "55,前金子\r",
      "\r\n",
      "55,金子1\r",
      "\r\n",
      "55,子19\r",
      "\r\n",
      "55,199\r",
      "\r\n",
      "56,名前中\r",
      "\r\n",
      "56,前中山\r",
      "\r\n",
      "56,中山1\r",
      "\r\n",
      "56,山19\r",
      "\r\n",
      "56,199\r",
      "\r\n",
      "57,名前和\r",
      "\r\n",
      "57,前和田\r",
      "\r\n",
      "57,和田1\r",
      "\r\n",
      "57,田19\r",
      "\r\n",
      "57,199\r",
      "\r\n",
      "58,名前石\r",
      "\r\n",
      "58,前石田\r",
      "\r\n",
      "58,石田1\r",
      "\r\n",
      "58,田19\r",
      "\r\n",
      "58,199\r",
      "\r\n",
      "59,名前工\r",
      "\r\n",
      "59,前工藤\r",
      "\r\n",
      "59,工藤1\r",
      "\r\n",
      "59,藤19\r",
      "\r\n",
      "59,199\r",
      "\r\n",
      "60,名前上\r",
      "\r\n",
      "60,前上田\r",
      "\r\n",
      "60,上田1\r",
      "\r\n",
      "60,田19\r",
      "\r\n",
      "60,199\r",
      "\r\n",
      "61,名前原\r",
      "\r\n",
      "61,前原1\r",
      "\r\n",
      "61,原19\r",
      "\r\n",
      "61,199\r",
      "\r\n",
      "62,名前森\r",
      "\r\n",
      "62,前森田\r",
      "\r\n",
      "62,森田1\r",
      "\r\n",
      "62,田19\r",
      "\r\n",
      "62,199\r",
      "\r\n",
      "63,名前酒\r",
      "\r\n",
      "63,前酒井\r",
      "\r\n",
      "63,酒井1\r",
      "\r\n",
      "63,井19\r",
      "\r\n",
      "63,199\r",
      "\r\n",
      "64,名前横\r",
      "\r\n",
      "64,前横山\r",
      "\r\n",
      "64,横山1\r",
      "\r\n",
      "64,山19\r",
      "\r\n",
      "64,199\r",
      "\r\n",
      "65,名前柴\r",
      "\r\n",
      "65,前柴田\r",
      "\r\n",
      "65,柴田1\r",
      "\r\n",
      "65,田19\r",
      "\r\n",
      "65,199\r",
      "\r\n",
      "66,名前宮\r",
      "\r\n",
      "66,前宮崎\r",
      "\r\n",
      "66,宮崎1\r",
      "\r\n",
      "66,崎19\r",
      "\r\n",
      "66,199\r",
      "\r\n",
      "67,名前宮\r",
      "\r\n",
      "67,前宮本\r",
      "\r\n",
      "67,宮本1\r",
      "\r\n",
      "67,本19\r",
      "\r\n",
      "67,199\r",
      "\r\n",
      "68,名前内\r",
      "\r\n",
      "68,前内田\r",
      "\r\n",
      "68,内田1\r",
      "\r\n",
      "68,田19\r",
      "\r\n",
      "68,199\r",
      "\r\n",
      "69,名前高\r",
      "\r\n",
      "69,前高木\r",
      "\r\n",
      "69,高木1\r",
      "\r\n",
      "69,木19\r",
      "\r\n",
      "69,199\r",
      "\r\n",
      "70,名前谷\r",
      "\r\n",
      "70,前谷口\r",
      "\r\n",
      "70,谷口1\r",
      "\r\n",
      "70,口19\r",
      "\r\n",
      "70,199\r",
      "\r\n",
      "71,名前安\r",
      "\r\n",
      "71,前安藤\r",
      "\r\n",
      "71,安藤1\r",
      "\r\n",
      "71,藤19\r",
      "\r\n",
      "71,199\r",
      "\r\n",
      "72,名前丸\r",
      "\r\n",
      "72,前丸山\r",
      "\r\n",
      "72,丸山1\r",
      "\r\n",
      "72,山19\r",
      "\r\n",
      "72,199\r",
      "\r\n",
      "73,名前今\r",
      "\r\n",
      "73,前今井\r",
      "\r\n",
      "73,今井1\r",
      "\r\n",
      "73,井19\r",
      "\r\n",
      "73,199\r",
      "\r\n",
      "74,名前大\r",
      "\r\n",
      "74,前大野\r",
      "\r\n",
      "74,大野1\r",
      "\r\n",
      "74,野19\r",
      "\r\n",
      "74,199\r",
      "\r\n",
      "75,名前高\r",
      "\r\n",
      "75,前高田\r",
      "\r\n",
      "75,高田1\r",
      "\r\n",
      "75,田19\r",
      "\r\n",
      "75,199\r",
      "\r\n",
      "76,名前菅\r",
      "\r\n",
      "76,前菅原\r",
      "\r\n",
      "76,菅原1\r",
      "\r\n",
      "76,原19\r",
      "\r\n",
      "76,199\r",
      "\r\n",
      "77,名前河\r",
      "\r\n",
      "77,前河野\r",
      "\r\n",
      "77,河野1\r",
      "\r\n",
      "77,野19\r",
      "\r\n",
      "77,199\r",
      "\r\n",
      "78,名前武\r",
      "\r\n",
      "78,前武田\r",
      "\r\n",
      "78,武田1\r",
      "\r\n",
      "78,田19\r",
      "\r\n",
      "78,199\r",
      "\r\n",
      "79,名前藤\r",
      "\r\n",
      "79,前藤本\r",
      "\r\n",
      "79,藤本1\r",
      "\r\n",
      "79,本19\r",
      "\r\n",
      "79,199\r",
      "\r\n",
      "80,名前上\r",
      "\r\n",
      "80,前上野\r",
      "\r\n",
      "80,上野1\r",
      "\r\n",
      "80,野19\r",
      "\r\n",
      "80,199\r",
      "\r\n",
      "81,名前杉\r",
      "\r\n",
      "81,前杉山\r",
      "\r\n",
      "81,杉山1\r",
      "\r\n",
      "81,山19\r",
      "\r\n",
      "81,199\r",
      "\r\n",
      "82,名前千\r",
      "\r\n",
      "82,前千葉\r",
      "\r\n",
      "82,千葉1\r",
      "\r\n",
      "82,葉19\r",
      "\r\n",
      "82,199\r",
      "\r\n",
      "83,名前村\r",
      "\r\n",
      "83,前村田\r",
      "\r\n",
      "83,村田1\r",
      "\r\n",
      "83,田19\r",
      "\r\n",
      "83,199\r",
      "\r\n",
      "84,名前増\r",
      "\r\n",
      "84,前増田\r",
      "\r\n",
      "84,増田1\r",
      "\r\n",
      "84,田19\r",
      "\r\n",
      "84,199\r",
      "\r\n",
      "85,名前小\r",
      "\r\n",
      "85,前小島\r",
      "\r\n",
      "85,小島1\r",
      "\r\n",
      "85,島19\r",
      "\r\n",
      "85,199\r",
      "\r\n",
      "86,名前小\r",
      "\r\n",
      "86,前小山\r",
      "\r\n",
      "86,小山1\r",
      "\r\n",
      "86,山19\r",
      "\r\n",
      "86,199\r",
      "\r\n",
      "87,名前大\r",
      "\r\n",
      "87,前大塚\r",
      "\r\n",
      "87,大塚1\r",
      "\r\n",
      "87,塚19\r",
      "\r\n",
      "87,199\r",
      "\r\n",
      "88,名前平\r",
      "\r\n",
      "88,前平野\r",
      "\r\n",
      "88,平野1\r",
      "\r\n",
      "88,野19\r",
      "\r\n",
      "88,199\r",
      "\r\n",
      "89,名前久\r",
      "\r\n",
      "89,前久保\r",
      "\r\n",
      "89,久保1\r",
      "\r\n",
      "89,保19\r",
      "\r\n",
      "89,199\r",
      "\r\n",
      "90,名前渡\r",
      "\r\n",
      "90,前渡部\r",
      "\r\n",
      "90,渡部1\r",
      "\r\n",
      "90,部19\r",
      "\r\n",
      "90,199\r",
      "\r\n",
      "91,名前松\r",
      "\r\n",
      "91,前松井\r",
      "\r\n",
      "91,松井1\r",
      "\r\n",
      "91,井19\r",
      "\r\n",
      "91,199\r",
      "\r\n",
      "92,名前菊\r",
      "\r\n",
      "92,前菊地\r",
      "\r\n",
      "92,菊地1\r",
      "\r\n",
      "92,地19\r",
      "\r\n",
      "92,199\r",
      "\r\n",
      "93,名前岩\r",
      "\r\n",
      "93,前岩崎\r",
      "\r\n",
      "93,岩崎1\r",
      "\r\n",
      "93,崎19\r",
      "\r\n",
      "93,199\r",
      "\r\n",
      "94,名前松\r",
      "\r\n",
      "94,前松尾\r",
      "\r\n",
      "94,松尾1\r",
      "\r\n",
      "94,尾19\r",
      "\r\n",
      "94,199\r",
      "\r\n",
      "95,名前佐\r",
      "\r\n",
      "95,前佐野\r",
      "\r\n",
      "95,佐野1\r",
      "\r\n",
      "95,野19\r",
      "\r\n",
      "95,199\r",
      "\r\n",
      "96,名前木\r",
      "\r\n",
      "96,前木下\r",
      "\r\n",
      "96,木下1\r",
      "\r\n",
      "96,下19\r",
      "\r\n",
      "96,199\r",
      "\r\n",
      "97,名前野\r",
      "\r\n",
      "97,前野口\r",
      "\r\n",
      "97,野口1\r",
      "\r\n",
      "97,口19\r",
      "\r\n",
      "97,199\r",
      "\r\n",
      "98,名前野\r",
      "\r\n",
      "98,前野村\r",
      "\r\n",
      "98,野村1\r",
      "\r\n",
      "98,村19\r",
      "\r\n",
      "98,199\r",
      "\r\n",
      "99,名前新\r",
      "\r\n",
      "99,前新1\r",
      "\r\n",
      "99,新19\r",
      "\r\n",
      "99,199\r",
      "\r\n",
      "100,名前1\r",
      "\r\n",
      "100,前19\r",
      "\r\n",
      "100,199\r",
      "\r\n",
      "101,名前1\r",
      "\r\n",
      "101,前19\r",
      "\r\n",
      "101,199\r",
      "\r\n",
      "102,名前1\r",
      "\r\n",
      "102,前19\r",
      "\r\n",
      "102,199\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "def ngram(words, n):\n",
    "\n",
    "    return list(zip(*(words[i:] for i in range(n))))\n",
    "\n",
    "def con(num, text):\n",
    "    s = '{},'.format(num)\n",
    "    for i in text:\n",
    "        s += i\n",
    "    return s.split(',') \n",
    "\n",
    "\n",
    "cc = []\n",
    "num_ngram = 3\n",
    "for num in range(len(t_p)):\n",
    "    text_parts = t_p[num]\n",
    "    n = ngram(text_parts, num_ngram)\n",
    "    c = [con(num, t) for t in ngram(text_parts, num_ngram)]\n",
    "    cc.append(c)\n",
    "    \n",
    "import csv\n",
    "with open(\"training_data.csv\", \"w\", newline='') as f:\n",
    "    w = csv.writer(f, delimiter=\",\")\n",
    "    w.writerow(['label', 'text'])\n",
    "    for c in cc:\n",
    "        for  data_list in c:       \n",
    "            w.writerow(data_list)\n",
    "\n",
    "            \n",
    "!cat training_data.csv            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "佐藤\r",
      "\r\n",
      "鈴木\r",
      "\r\n",
      "高橋\r",
      "\r\n",
      "田中\r",
      "\r\n",
      "伊藤\r",
      "\r\n",
      "山本\r",
      "\r\n",
      "渡辺\r",
      "\r\n",
      "中村\r",
      "\r\n",
      "小林\r",
      "\r\n",
      "加藤\r",
      "\r\n",
      "吉田\r",
      "\r\n",
      "山田\r",
      "\r\n",
      "木\r",
      "\r\n",
      "山口\r",
      "\r\n",
      "松本\r",
      "\r\n",
      "井上\r",
      "\r\n",
      "木村\r",
      "\r\n",
      "林\r",
      "\r\n",
      "斎藤\r",
      "\r\n",
      "清水\r",
      "\r\n",
      "山崎\r",
      "\r\n",
      "阿部\r",
      "\r\n",
      "森\r",
      "\r\n",
      "池田\r",
      "\r\n",
      "橋本\r",
      "\r\n",
      "山下\r",
      "\r\n",
      "石川\r",
      "\r\n",
      "中島\r",
      "\r\n",
      "前田\r",
      "\r\n",
      "藤田\r",
      "\r\n",
      "後藤\r",
      "\r\n",
      "小川\r",
      "\r\n",
      "岡田\r",
      "\r\n",
      "村上\r",
      "\r\n",
      "長谷川\r",
      "\r\n",
      "近藤\r",
      "\r\n",
      "石井\r",
      "\r\n",
      "斉藤\r",
      "\r\n",
      "坂本\r",
      "\r\n",
      "遠藤\r",
      "\r\n",
      "藤井\r",
      "\r\n",
      "青木\r",
      "\r\n",
      "福田\r",
      "\r\n",
      "三浦\r",
      "\r\n",
      "西村\r",
      "\r\n",
      "藤原\r",
      "\r\n",
      "太田\r",
      "\r\n",
      "松田\r",
      "\r\n",
      "原田\r",
      "\r\n",
      "岡本\r",
      "\r\n",
      "中野\r",
      "\r\n",
      "中川\r",
      "\r\n",
      "小野\r",
      "\r\n",
      "田村\r",
      "\r\n",
      "竹内\r",
      "\r\n",
      "金子\r",
      "\r\n",
      "中山\r",
      "\r\n",
      "和田\r",
      "\r\n",
      "石田\r",
      "\r\n",
      "工藤\r",
      "\r\n",
      "上田\r",
      "\r\n",
      "原\r",
      "\r\n",
      "森田\r",
      "\r\n",
      "酒井\r",
      "\r\n",
      "横山\r",
      "\r\n",
      "柴田\r",
      "\r\n",
      "宮崎\r",
      "\r\n",
      "宮本\r",
      "\r\n",
      "内田\r",
      "\r\n",
      "高木\r",
      "\r\n",
      "谷口\r",
      "\r\n",
      "安藤\r",
      "\r\n",
      "丸山\r",
      "\r\n",
      "今井\r",
      "\r\n",
      "大野\r",
      "\r\n",
      "高田\r",
      "\r\n",
      "菅原\r",
      "\r\n",
      "河野\r",
      "\r\n",
      "武田\r",
      "\r\n",
      "藤本\r",
      "\r\n",
      "上野\r",
      "\r\n",
      "杉山\r",
      "\r\n",
      "千葉\r",
      "\r\n",
      "村田\r",
      "\r\n",
      "増田\r",
      "\r\n",
      "小島\r",
      "\r\n",
      "小山\r",
      "\r\n",
      "大塚\r",
      "\r\n",
      "平野\r",
      "\r\n",
      "久保\r",
      "\r\n",
      "渡部\r",
      "\r\n",
      "松井\r",
      "\r\n",
      "菊地\r",
      "\r\n",
      "岩崎\r",
      "\r\n",
      "松尾\r",
      "\r\n",
      "佐野\r",
      "\r\n",
      "木下\r",
      "\r\n",
      "野口\r",
      "\r\n",
      "野村\r",
      "\r\n",
      "新\r",
      "\r\n",
      "\"\"\r",
      "\r\n",
      "\"\"\r",
      "\r\n",
      "\"\"\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# 回答データの作成\n",
    "\n",
    "name_list = [[n] for n in name_list]\n",
    "\n",
    "with open(\"replies.csv\", \"w\", newline='') as f:\n",
    "    w = csv.writer(f, delimiter=\",\")\n",
    "    for  data_list in name_list:\n",
    "        w.writerow(data_list)\n",
    "        \n",
    "        \n",
    "!cat replies.csv       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mecab\n",
      "  Downloading mecab-0.996.2.tar.gz (62 kB)\n",
      "\u001b[K     |████████████████████████████████| 62 kB 1.9 MB/s eta 0:00:011\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /usr/local/bin/python -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-1m36i1x9/mecab/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-1m36i1x9/mecab/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-install-1m36i1x9/mecab/pip-egg-info\n",
      "         cwd: /tmp/pip-install-1m36i1x9/mecab/\n",
      "    Complete output (10 lines):\n",
      "    /bin/sh: 1: mecab-config: not found\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-install-1m36i1x9/mecab/setup.py\", line 53, in <module>\n",
      "        include_dirs=cmd2(\"mecab-config --inc-dir\"),\n",
      "      File \"/tmp/pip-install-1m36i1x9/mecab/setup.py\", line 19, in cmd2\n",
      "        return cmd1(strings).split()\n",
      "      File \"/tmp/pip-install-1m36i1x9/mecab/setup.py\", line 15, in cmd1\n",
      "        return os.popen(strings).readlines()[0].rstrip()\n",
      "    IndexError: list index out of range\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[31mERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install mecab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-0.22.2.post1-cp38-cp38-manylinux1_x86_64.whl (7.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.0 MB 6.1 MB/s eta 0:00:01     |█████████████████▊              | 3.9 MB 6.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scipy>=0.17.0\n",
      "  Downloading scipy-1.4.1-cp38-cp38-manylinux1_x86_64.whl (26.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 26.0 MB 20.7 MB/s eta 0:00:01    |█████▏                          | 4.2 MB 22.9 MB/s eta 0:00:01     |██████████████████▊             | 15.2 MB 22.9 MB/s eta 0:00:01     |█████████████████████▍          | 17.4 MB 20.7 MB/s eta 0:00:01     |██████████████████████▎         | 18.1 MB 20.7 MB/s eta 0:00:01     |██████████████████████████▋     | 21.6 MB 20.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.18.2)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-0.14.1-py2.py3-none-any.whl (294 kB)\n",
      "\u001b[K     |████████████████████████████████| 294 kB 26.6 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1315 sha256=50047aa4ae7ae13f9ab64a014c79a2fe3c5c56f9ca4f1ef7924779310f1a25d4\n",
      "  Stored in directory: /root/.cache/pip/wheels/22/0b/40/fd3f795caaa1fb4c6cb738bc1f56100be1e57da95849bfc897\n",
      "Successfully built sklearn\n",
      "Installing collected packages: scipy, joblib, scikit-learn, sklearn\n",
      "Successfully installed joblib-0.14.1 scikit-learn-0.22.2.post1 scipy-1.4.1 sklearn-0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "長谷川\n",
      "こんにちは中村でした。\n",
      "AI reply: 中村\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from os.path import dirname, join, normpath\n",
    "\n",
    "import MeCab\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "class DialogueAgent:\n",
    "    def __init__(self):\n",
    "        self.tagger = MeCab.Tagger()\n",
    "\n",
    "    def _tokenize(self, text): # 形態素解析\n",
    "        node = self.tagger.parseToNode(text)\n",
    "\n",
    "        tokens = []\n",
    "        while node:\n",
    "            if node.surface != '':\n",
    "                tokens.append(node.surface)\n",
    " \n",
    "            node = node.next\n",
    "        return tokens\n",
    "\n",
    "    def train(self, texts, labels): # 2. 文章とラベルからニューラルネットワークを更新\n",
    "        pipeline = Pipeline([\n",
    "            ('vecttorizer', CountVectorizer(tokenizer=self._tokenize)), \n",
    "            ('classifier', SVC()),\n",
    "        ])\n",
    "        pipeline.fit(texts, labels)\n",
    "        self.pipeline = pipeline\n",
    "\n",
    "    def predict(self, texts): # 3. 他の文章でのニューロンの反応をチェック\n",
    "        return self.pipeline.predict(texts)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    BASE_DIR = normpath(dirname('__file__'))\n",
    "\n",
    "    training_data = pd.read_csv(join(BASE_DIR, './training_data.csv'))  # 学習用読み込み文章\n",
    "\n",
    "    dialogue_agent = DialogueAgent()\n",
    "    dialogue_agent.train(training_data['text'], training_data['label']) # 学習用読み込み文章とラベルの組を学習\n",
    "\n",
    "    with open(join(BASE_DIR, './replies.csv')) as f:  # 応答文章\n",
    "        replies = f.read().split('\\n')\n",
    "\n",
    "    input_text = '長a谷w川'\n",
    "    predictions = dialogue_agent.predict([input_text]) \n",
    "    predicted_class_id = predictions[0]  \n",
    "\n",
    "    print(replies[predicted_class_id])\n",
    "\n",
    "    while True:\n",
    "        input_text = input()\n",
    "        predictions = dialogue_agent.predict([input_text])\n",
    "        predicted_class_id = predictions[0]\n",
    "\n",
    "        print('AI reply: ' + replies[predicted_class_id])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "mecab is already the newest version (0.996-6).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 5 not upgraded.\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following NEW packages will be installed:\n",
      "  libmecab-dev\n",
      "0 upgraded, 1 newly installed, 0 to remove and 5 not upgraded.\n",
      "Need to get 309 kB of archives.\n",
      "After this operation, 3122 kB of additional disk space will be used.\n",
      "Get:1 http://deb.debian.org/debian buster/main amd64 libmecab-dev amd64 0.996-6 [309 kB]\n",
      "Fetched 309 kB in 0s (4640 kB/s)    \u001b[0m\u001b[33m\n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "\n",
      "\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package libmecab-dev.\n",
      "(Reading database ... 25297 files and directories currently installed.)\n",
      "Preparing to unpack .../libmecab-dev_0.996-6_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 20%]\u001b[49m\u001b[39m [###########...............................................] \u001b8Unpacking libmecab-dev (0.996-6) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 40%]\u001b[49m\u001b[39m [#######################...................................] \u001b8Setting up libmecab-dev (0.996-6) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 60%]\u001b[49m\u001b[39m [##################################........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 80%]\u001b[49m\u001b[39m [##############################################............] \u001b8\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  mecab-ipadic\n",
      "The following NEW packages will be installed:\n",
      "  mecab-ipadic mecab-ipadic-utf8\n",
      "0 upgraded, 2 newly installed, 0 to remove and 5 not upgraded.\n",
      "Need to get 6719 kB of archives.\n",
      "After this operation, 54.4 MB of additional disk space will be used.\n",
      "Do you want to continue? [Y/n] "
     ]
    }
   ],
   "source": [
    "!apt install mecab\n",
    "!apt install libmecab-dev\n",
    "!apt install mecab-ipadic-utf8\n",
    "#!pip install mecab"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
